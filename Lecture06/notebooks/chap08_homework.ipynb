{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"chap08_homework.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"SI0CCRYGbsLX"},"source":["# 第6回講義 宿題"]},{"cell_type":"markdown","metadata":{"id":"jhZjl_2gbsLf"},"source":["## 課題\n","RNNを用いてIMDbのsentiment analysisを実装してみましょう。\n","\n","ネットワークの形などは特に制限を設けませんし、今回のLessonで扱った内容以外の工夫も組み込んでもらって構いません。"]},{"cell_type":"markdown","metadata":{"id":"NBcfs2VybsLj"},"source":["## 目標値\n","F値：0.85"]},{"cell_type":"markdown","metadata":{"id":"tZj-U7SvbsLl"},"source":["## ルール\n","- 以下のセルで指定されている`train_data`以外の学習データは使わないでください。\n","- `test_data`の正解ラベルを参照しないでください。"]},{"cell_type":"markdown","metadata":{"id":"jm9ZJX2TbsLo"},"source":["## 提出方法\n","- 2つのファイルを提出していただきます。\n","  1. テストデータ (x_test) に対する予測ラベルを`submission_pred.csv`として保存し、Homeworkタブから**chap08**を選択して提出してください。\n","  2. それに対応するpythonのコードを`submission_code.py`として保存し、Homeworkタブから**chap08 (code)**を選択して提出してください。\n","    - セルに書いたコードを.py形式で保存するためには%%writefileコマンドなどを利用してください。\n","    - writefileコマンドではファイルの保存のみが行われセル内のpythonコード自体は実行されません。そのため、実際にコードを走らせる際にはwritefileコマンドをコメントアウトしてください\n","\n","\n","- コードの内容を変更した場合は、1と2の両方を提出し直してください。\n","\n","- なお、採点は1で行い、2はコードの確認用として利用します。(成績優秀者はコード内容を公開させていただくかもしれません。)\n","\n","- **宿題の締め切りは【出題週の翌週水曜日24時】です。**"]},{"cell_type":"markdown","metadata":{"id":"ejdA6CESbsLs"},"source":["## 評価方法\n","\n","- 予測ラベルの（`t_test`に対する）F値で評価します。\n","- 定時に評価しLeader Boardを更新します。\n","- 締切後のF値でLeader Boardを更新します。これを最終的な評価とします。"]},{"cell_type":"markdown","metadata":{"id":"IjSgBf1ibsLw"},"source":["## データの読み込み（このセルは修正しないでください）"]},{"cell_type":"code","metadata":{"id":"4X9ptijybsLz"},"source":["import numpy as np\n","import torch\n","import torchtext.legacy\n","from torchtext.legacy import data\n","from torchtext.legacy import datasets\n","from sklearn.utils import shuffle\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","import string\n","import re\n","\n","rng = np.random.RandomState(1234)\n","random_state = 42\n","\n","\n","def preprocessing_text(text):\n","    # 改行コードを消去\n","    text = re.sub('<br />', '', text)\n","\n","    # カンマ、ピリオド以外の記号をスペースに置換\n","    for p in string.punctuation:\n","        if (p == \".\") or (p == \",\"):\n","            continue\n","        else:\n","            text = text.replace(p, \" \")\n","\n","    # ピリオドなどの前後にはスペースを入れておく\n","    text = text.replace(\".\", \" . \")\n","    text = text.replace(\",\", \" , \")\n","    return text\n","\n","# 分かち書き（今回はデータが英語で、簡易的にスペースで区切る）\n","\n","\n","def tokenizer_punctuation(text):\n","    return text.strip().split()\n","\n","\n","# 前処理と分かち書きをまとめた関数を定義\n","def tokenizer_with_preprocessing(text):\n","    text = preprocessing_text(text)\n","    ret = tokenizer_punctuation(text)\n","    return ret\n","\n","\n","# 文章とラベルの両方に用意します\n","max_length = 256\n","TEXT = data.Field(sequential=True, tokenize=tokenizer_with_preprocessing,\n","                  use_vocab=True, lower=True, include_lengths=True,\n","                  batch_first=True, fix_length=max_length,\n","                  init_token=\"<cls>\", eos_token=\"<eos>\")\n","LABEL = data.Field(sequential=False, use_vocab=True)\n","\n","# 引数の意味は次の通り\n","# init_token：全部の文章で、文頭に入れておく単語\n","# eos_token：全部の文章で、文末に入れておく単語\n","\n","\n","# データセットの作成\n","\n","train_data, test_data = datasets.IMDB.splits(text_field=TEXT,\n","                                             label_field=LABEL)\n","\n","for i in range(len(test_data)):\n","    if i % 2 == 0:\n","        test_data[i].label = \"pos\"\n","    else:\n","        test_data[i].label = \"neg\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h06XX2xFijZW"},"source":["train_data, valid_data = train_data.split(0.8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WIKgr01wbsL5"},"source":["## 実装"]},{"cell_type":"code","metadata":{"id":"w6j2soNLbsL7"},"source":["import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import torch.nn.functional as F\n","\n","word_num = 3000\n","TEXT.build_vocab(train_data, max_size=word_num)\n","LABEL.build_vocab(train_data)\n","\n","batch_size = 100\n","\n","train_dl = torchtext.legacy.data.Iterator(train_data, batch_size=batch_size,\n","                                   train=True, sort=True)\n","\n","valid_dl = torchtext.legacy.data.Iterator(valid_data, batch_size=batch_size,\n","                                   train=False, sort=False)\n","\n","test_dl = torchtext.legacy.data.Iterator(test_data, batch_size=batch_size,\n","                                  train=False, sort=False)\n","\n","\n","def torch_log(x):\n","    return torch.log(torch.clamp(x, min=1e-10))\n","\n","\n","class Embedding(nn.Module):\n","    # WRITE ME\n","\n","class SequenceTaggingNet(nn.Module):\n","    # WRITE ME\n","\n","\n","emb_dim = 100\n","hid_dim = 50\n","n_epochs = 10\n","device = 'cuda'\n","\n","net = SequenceTaggingNet(word_num + 4, emb_dim, hid_dim)\n","net.to(device)\n","optimizer = optim.Adam(net.parameters())\n","\n","for epoch in range(n_epochs):\n","    losses_train = []\n","    losses_valid = []\n","\n","    net.train()\n","    n_train = 0\n","    acc_train = 0\n","    for mini_batch in train_dl:\n","\n","        # WRITE ME\n","\n","        losses_train.append(loss.tolist())\n","\n","        n_train += t.size()[0]\n","\n","    # Valid\n","    t_valid = []\n","    y_pred = []\n","    net.eval()\n","    for mini_batch in valid_dl:\n","\n","        # WRITE ME\n","\n","        t_valid.extend(t.tolist())\n","        y_pred.extend(pred.tolist())\n","\n","        losses_valid.append(loss.tolist())\n","\n","    print('EPOCH: {}, Train Loss: {:.3f}, Valid Loss: {:.3f}, Validation F1: {:.3f}'.format(\n","        epoch,\n","        np.mean(losses_train),\n","        np.mean(losses_valid),\n","        f1_score(t_valid, y_pred, average='macro')\n","    ))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQ8xtUcHj6IR"},"source":["net.eval()\n","\n","y_pred = []\n","for mini_batch in test_dl:\n","\n","    x = mini_batch.text[0].to(device)\n","    len_seq = mini_batch.text[1].to(device)\n","    h = net(x, torch.max(len_seq), len_seq)\n","    y = torch.sigmoid(h).squeeze()\n","\n","    pred = y.round().squeeze()  # 0.5以上の値を持つ要素を正ラベルと予測する\n","\n","    y_pred.extend(pred.tolist())\n","\n","\n","submission = pd.Series(y_pred, name='label')\n","submission.to_csv('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210520/submission_pred.csv', header=True, index_label='id')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ywq-XBEc0DKe"},"source":[""],"execution_count":null,"outputs":[]}]}