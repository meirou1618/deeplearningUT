{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"chap06_homework.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python388jvsc74a57bd0514466fe9bdbb4465d0f72d486e68777ccb9801e0d08f857a8c5a4c505647bc4","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MUWcdth_khfN"},"source":["# 第4回講義 宿題"]},{"cell_type":"markdown","metadata":{"id":"gAjuP7I4lWyn"},"source":["## 課題\n","\n","CNNを用いて、FashionMNISTの高精度な分類器を実装してみましょう。\n","モデルのレイヤーを変更してみるなどして精度の向上にチャンレンジして下さい。 精度上位者はリーダーボードに載ります。"]},{"cell_type":"markdown","metadata":{"id":"Cpiz19GRlZ_9"},"source":["### 目標値\n","\n","Accuracy 93%"]},{"cell_type":"markdown","metadata":{"id":"qSHeI_utleEN"},"source":["\n","### ルール\n","\n","- 訓練データはx_train、 t_train、テストデータはx_testで与えられます。\n","- 予測ラベルは one_hot表現ではなく0~9のクラスラベル で表してください。\n","- **下のセルで指定されているx_train、t_train以外の学習データは使わないでください。**\n","- ただし、**torch.nn.Conv2dのような高レベルのAPIは使用しないで下さい。**具体的には、nn.Parameter, nn.Module, nn.Sequential, nn.functional以外のnn系のAPIです。\n","- torchvision等で既に実装されているモデルも使用しないで下さい。"]},{"cell_type":"markdown","metadata":{"id":"diuec-_YluI6"},"source":["### 提出方法\n","\n","- 2つのファイルを提出していただきます。\n","  - テストデータ (x_test) に対する予測ラベルをcsvファイル (ファイル名: submission_pred.csv) で提出してください。\n","  - それに対応するpythonのコードをsubmission_code.pyとして提出してください (%%writefileコマンドなどを利用してください)。"]},{"cell_type":"markdown","metadata":{"id":"hofSzJsVlvKp"},"source":["### 評価方法\n","\n","- 予測ラベルのt_testに対する精度 (Accuracy) で評価します。\n","- 定時に採点しLeader Boardを更新します。(採点スケジュールは別アナウンス）\n","- 締切後の点数を最終的な評価とします。"]},{"cell_type":"markdown","metadata":{"id":"Cu4cmQtelx19"},"source":["### データの読み込み\n","\n","- この部分は修正しないでください"]},{"cell_type":"code","metadata":{"id":"EsLDDSUJkRx-"},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import torch.nn.functional as F\n","import inspect\n","\n","nn_except = [\"Module\", \"Parameter\", \"Sequential\", \"functional\"]\n","for m in inspect.getmembers(nn):\n","    if not m[0] in nn_except and m[0][0:2] != \"__\":\n","        delattr(nn, m[0]) \n","\n","\"\"\"\n","#学習データ\n","x_train = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210506/data/x_train.npy')\n","t_train = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210506/data/t_train.npy')\n","    \n","#テストデータ\n","x_test = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210506/data/x_test.npy')\n","\"\"\"\n","#学習データ\n","x_train = np.load('/home/sato.mizuki/deeplearningUT/Lecture04/data/x_train.npy')\n","t_train = np.load('/home/sato.mizuki/deeplearningUT/Lecture04/data/t_train.npy')\n","    \n","#テストデータ\n","x_test = np.load('/home/sato.mizuki/deeplearningUT/Lecture04/data/x_test.npy')\n","\n","\n","class train_dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_train, t_train):\n","        self.x_train = x_train.reshape(-1, 1, 28, 28).astype('float32') / 255\n","        self.t_train = t_train\n","\n","    def __len__(self):\n","        return self.x_train.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.x_train[idx], dtype=torch.float), torch.tensor(t_train[idx], dtype=torch.long)\n","\n","class test_dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_test):\n","        self.x_test = x_test.reshape(-1, 1, 28, 28).astype('float32') / 255\n","\n","    def __len__(self):\n","        return self.x_test.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.x_test[idx], dtype=torch.float)\n","\n","trainval_data = train_dataset(x_train, t_train)\n","test_data = test_dataset(x_test)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UrSpHDIWOfK_"},"source":["### 畳み込みニューラルネットワーク(CNN)の実装"]},{"cell_type":"code","metadata":{"id":"sKAe0F36nSvU"},"source":["batch_size = 32\n","\n","val_size = 10000\n","train_size = len(trainval_data) - val_size\n","\n","train_data, val_data = torch.utils.data.random_split(trainval_data, [train_size, val_size])\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    train_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_valid = torch.utils.data.DataLoader(\n","    val_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_test = torch.utils.data.DataLoader(\n","    test_data,\n","    batch_size=batch_size,\n","    shuffle=False\n",")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"PADQiKNa2snb"},"source":["rng = np.random.RandomState(1234)\n","random_state = 42\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","class Conv(nn.Module):\n","    # WRITE ME\n","    def __init__(self, filter_shape, function=lambda x: x, stride=(1, 1), padding=0):\n","        super().__init__()\n","        # Heの初期値\n","        fan_in = filter_shape[1] * filter_shape[2] * filter_shape[3]\n","        # filter_shape: (出力チャンネル数)x(入力チャンネル数)x(縦の次元数)x(横の次元数)\n","        fan_out = filter_shape[0] * filter_shape[2] * filter_shape[3]\n","\n","        self.W = nn.Parameter(torch.tensor(rng.uniform(\n","                        -np.sqrt(6/fan_in),\n","                        np.sqrt(6/fan_in),\n","                        size=filter_shape\n","                    ).astype('float32')))\n","\n","        # バイアスはフィルタごとなので, 出力フィルタ数と同じ次元数\n","        self.b = nn.Parameter(torch.tensor(np.zeros((filter_shape[0]), dtype='float32')))\n","        self.function = function\n","        self.stride = stride\n","        self.padding = padding\n","        \n","    def forward(self, x):\n","        u = F.conv2d(x, self.W, bias=self.b, stride=self.stride, padding=self.padding)\n","        return self.function(u)\n","\n","\n","class Pooling(nn.Module):\n","    # WRITE ME\n","    def __init__(self, ksize=(2, 2), stride=(2, 2), padding=0):\n","        super().__init__()\n","        self.ksize = ksize\n","        self.stride = stride\n","        self.padding = padding\n","\n","    def forward(self, x):\n","        return F.avg_pool2d(x, kernel_size=self.ksize, stride=self.stride, padding=self.padding)\n","\n","\n","class Flatten(nn.Module):\n","    # WRITE ME\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return x.view(x.size()[0], -1)\n","\n","\n","class Dense(nn.Module):\n","    # WRITE ME\n","    def __init__(self, in_dim, out_dim, function=lambda x: x):\n","        super().__init__()\n","        # He Initialization\n","        # in_dim: 入力の次元数、out_dim: 出力の次元数              \n","        self.W = nn.Parameter(torch.tensor(rng.uniform(\n","                        -np.sqrt(6/in_dim),\n","                        np.sqrt(6/in_dim),\n","                        size=(in_dim, out_dim)\n","                    ).astype('float32')))\n","\n","        self.b = nn.Parameter(torch.tensor(np.zeros([out_dim]).astype('float32')))\n","        self.function = function\n","    def forward(self, x):\n","        return self.function(torch.matmul(x, self.W) + self.b)\n","\n","\n","conv_net = nn.Sequential(\n","    Conv((64, 1, 7, 7), F.relu, padding=3),                  #28,28,1 -> 28,28,64\n","    Pooling((2, 2)),                                         #28,28,64 -> 14,14,64\n","    Conv((128, 64, 3, 3), F.relu, padding=1),                #14,14,64 -> 14,14,128\n","    Pooling((2, 2), stride=(1,1)),                           #14,14,128 -> 13,13,128\n","    Conv((194, 128, 3, 3), F.relu, padding=1),               #13,13,128 -> 13,13,194\n","    Pooling((2, 2), stride=(1,1)),                           #13,13,194 -> 12,12,194\n","    Conv((194, 194, 3, 3), F.relu, padding=1),               #12,12,194 -> 12,12,194\n","    Pooling((2, 2)),                                         #12,12,194 -> 6,6,194\n","    Conv((388, 194, 3, 3), F.relu, padding=1),               #6,6,194 -> 6,6,388\n","    Pooling((2, 2)),                                         #6,6,388 -> 3,3,388\n","    Flatten(),\n","    Dense(3*3*388, 10)\n",")# WRITE ME\n","\"\"\"\n","    Conv((194, 128, 3, 3), F.relu, padding=1),               #3,3,128 -> 3,3,194\n","    Pooling((2, 2)),\n","    Conv((384, 194, 3, 3), F.relu, padding=1),  \n","    Pooling((2, 2)),\n","    Conv((256, 384, 3, 3), F.relu, padding=1),  \n","    Pooling((2, 2)),  \n","\"\"\"  \n","\n","n_epochs = 100\n","lr = 0.02\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","conv_net.to(device)\n","optimizer = optim.SGD(conv_net.parameters(), lr=lr) # WRITE ME"],"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 1, 28, 28])\ntensor([8, 1, 1, 8, 4, 8, 4, 2, 8, 6, 6, 6, 1, 5, 4, 9, 3, 0, 1, 5, 2, 0, 1, 0,\n        1, 3, 5, 9, 1, 1, 3, 3])\n"]}],"source":["for xx, tt in dataloader_train:\n","    break\n","print(xx.shape)\n","print(tt)"]},{"cell_type":"code","metadata":{"id":"nlOZuLu-328i"},"source":["import tqdm\n","for epoch in tqdm.tqdm(range(n_epochs)):\n","    losses_train = []\n","    losses_valid = []\n","    train_num = 0\n","    train_true_num = 0\n","    valid_num = 0\n","    valid_true_num = 0\n","\n","    conv_net.train()  # 訓練時には勾配を計算するtrainモードにする\n","    for x, t in dataloader_train:\n","        # WRITE ME\n","        conv_net.zero_grad()\n","        x = x.to(device)\n","        t_hot = torch.eye(10)[t] #10??\n","        t_hot = t_hot.to(device)\n","        y = conv_net.forward(x)\n","        loss = -(t_hot*torch.log_softmax(y, dim=-1)).sum(axis=1).mean()\n","        loss.backward()\n","        optimizer.step()\n","        pred = y.argmax(1)\n","\n","        losses_train.append(loss.tolist())\n","\n","        acc = torch.where(t - pred.to(\"cpu\") == 0, torch.ones_like(t), torch.zeros_like(t))\n","        train_num += acc.size()[0]\n","        train_true_num += acc.sum().item()\n","\n","    conv_net.eval()  # 評価時には勾配を計算しないevalモードにする\n","    for x, t in dataloader_valid:\n","        # WRITE ME\n","        conv_net.zero_grad()\n","        x = x.to(device)\n","        t_hot = torch.eye(10)[t] #10??\n","        t_hot = t_hot.to(device)\n","        y = conv_net.forward(x)\n","        loss = -(t_hot*torch.log_softmax(y, dim=-1)).sum(axis=1).mean()\n","        pred = y.argmax(1)\n","\n","        losses_valid.append(loss.tolist())\n","\n","        acc = torch.where(t - pred.to(\"cpu\") == 0, torch.ones_like(t), torch.zeros_like(t))\n","        valid_num += acc.size()[0]\n","        valid_true_num += acc.sum().item()\n","    if (epoch+1)%10==0:\n","        print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n","            epoch,\n","            np.mean(losses_train),\n","            train_true_num/train_num,\n","            np.mean(losses_valid),\n","            valid_true_num/valid_num\n","        ))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/100 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (32x388 and 3492x10)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-72c399635f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mt_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#10??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mt_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_hot\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-6ea03d767163>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x388 and 3492x10)"]}]},{"cell_type":"code","metadata":{"id":"Yq3scS5j4Rt2"},"source":["conv_net.eval()\n","\n","t_pred = []\n","for x in dataloader_test:\n","\n","    x = x.to(device)\n","\n","    # 順伝播\n","    y = conv_net.forward(x)\n","\n","    # モデルの出力を予測値のスカラーに変換\n","    pred = y.argmax(1).tolist()\n","\n","    t_pred.extend(pred)\n","\n","submission = pd.Series(t_pred, name='label')\n","\"\"\"\n","submission.to_csv('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210506/submission_pred.csv', header=True, index_label='id')\n","\"\"\"\n","import os\n","os.makedirs('output', exist_ok=True)\n","submission.to_csv('output/submission_pred_3_%d'%n_epochs+'.csv', header=True, index_label='id')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wuub_7Sqs_Dm"},"source":[],"execution_count":null,"outputs":[]}]}