{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"chap07_homework.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MUWcdth_khfN"},"source":["# 第5回講義 宿題"]},{"cell_type":"markdown","metadata":{"id":"gAjuP7I4lWyn"},"source":["## 課題\n","\n","今Lessonで学んだことに工夫を加えて、CNNでより高精度なCIFAR10の分類器を実装してみましょう。精度上位者はリーダーボードに載ります。"]},{"cell_type":"markdown","metadata":{"id":"Cpiz19GRlZ_9"},"source":["### 目標値\n","\n","Accuracy 78%"]},{"cell_type":"markdown","metadata":{"id":"qSHeI_utleEN"},"source":["### ルール\n","\n","- 訓練データはx_train、 t_train、テストデータはx_testで与えられます。\n","- 予測ラベルは one_hot表現ではなく0~9のクラスラベル で表してください。\n","- **下のセルで指定されているx_train、t_train以外の学習データは使わないでください。**\n","- 今回から基本的にAPI制限はありません。\n","- ただしtorchvision等の既存モデルや、学習済みモデルは用いないでください。"]},{"cell_type":"markdown","metadata":{"id":"diuec-_YluI6"},"source":["### 提出方法\n","\n","- 2つのファイルを提出していただきます。\n","  - テストデータ (x_test) に対する予測ラベルをcsvファイル (ファイル名: submission_pred.csv) で提出してください。\n","  - それに対応するpythonのコードをsubmission_code.pyとして提出してください (%%writefileコマンドなどを利用してください)。"]},{"cell_type":"markdown","metadata":{"id":"hofSzJsVlvKp"},"source":["### 評価方法\n","\n","- 予測ラベルのt_testに対する精度 (Accuracy) で評価します。\n","- 定時に採点しLeader Boardを更新します。(採点スケジュールは別アナウンス）\n","- 締切後の点数を最終的な評価とします。"]},{"cell_type":"markdown","metadata":{"id":"Cu4cmQtelx19"},"source":["### データの読み込み\n","\n","- この部分は修正しないでください"]},{"cell_type":"code","metadata":{"id":"EsLDDSUJkRx-"},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from torchvision import transforms\n","from tqdm import tqdm_notebook as tqdm\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","\n","#学習データ\n","x_train = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210513/data/x_train.npy')\n","t_train = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210513/data/t_train.npy')\n","    \n","#テストデータ\n","x_test = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210513/data/x_test.npy')\n","\n","class train_dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_train, t_train):\n","        data = x_train.astype('float32')\n","        self.x_train = []\n","        for i in range(data.shape[0]):\n","            self.x_train.append(Image.fromarray(np.uint8(data[i])))\n","        self.t_train = t_train\n","        self.transform = transforms.ToTensor()\n","\n","    def __len__(self):\n","        return len(self.x_train)\n","\n","    def __getitem__(self, idx):\n","        return self.transform(self.x_train[idx]), torch.tensor(t_train[idx], dtype=torch.long)\n","\n","class test_dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_test):\n","        data = x_test.astype('float32')\n","        self.x_test = []\n","        for i in range(data.shape[0]):\n","            self.x_test.append(Image.fromarray(np.uint8(data[i])))\n","        self.transform = transforms.ToTensor()\n","\n","    def __len__(self):\n","        return len(self.x_test)\n","\n","    def __getitem__(self, idx):\n","        return self.transform(self.x_test[idx])\n","\n","trainval_data = train_dataset(x_train, t_train)\n","test_data = test_dataset(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UrSpHDIWOfK_"},"source":["### 畳み込みニューラルネットワーク(CNN)の実装"]},{"cell_type":"code","metadata":{"id":"sKAe0F36nSvU"},"source":["class gcn():\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, x):\n","        mean = torch.mean(x)\n","        std = torch.std(x)\n","        return (x - mean)/(std + 10**(-6))  # 0除算を防ぐ\n","\n","\n","class ZCAWhitening():\n","    def __init__(self, epsilon=1e-4, device=\"cuda\"):  # 計算が重いのでGPUを用いる\n","        self.epsilon = epsilon\n","        self.device = device\n","\n","    def fit(self, images):  # 変換行列と平均をデータから計算\n","        x = images[0][0].reshape(1, -1)\n","        self.mean = torch.zeros([1, x.size()[1]]).to(self.device)\n","        con_matrix = torch.zeros([x.size()[1], x.size()[1]]).to(self.device)\n","        for i in range(len(images)):  # 各データについての平均を取る\n","            x = images[i][0].reshape(1, -1).to(self.device)\n","            self.mean += x / len(images)\n","            con_matrix += torch.mm(x.t(), x) / len(images)\n","            if i % 10000 == 0:\n","                print(\"{0}/{1}\".format(i, len(images)))\n","        self.E, self.V = torch.symeig(con_matrix, eigenvectors=True)  # 固有値分解\n","        self.E = torch.max(self.E, torch.zeros_like(self.E)) # 誤差の影響で負になるのを防ぐ\n","        self.ZCA_matrix = torch.mm(torch.mm(self.V, torch.diag((self.E.squeeze()+self.epsilon)**(-0.5))), self.V.t())\n","        print(\"completed!\")\n","\n","    def __call__(self, x):\n","        size = x.size()\n","        x = x.reshape(1, -1).to(self.device)\n","        x -= self.mean\n","        x = torch.mm(x, self.ZCA_matrix.t())\n","        x = x.reshape(tuple(size))\n","        x = x.to(\"cpu\")\n","        return x\n","\n","\n","# (datasetのクラスを自作したので、このあたりの処理が少し変わっています)\n","\n","zca = ZCAWhitening()\n","zca.fit(trainval_data)\n","\n","val_size = 3000\n","train_data, val_data = torch.utils.data.random_split(trainval_data, [len(trainval_data)-val_size, val_size])\n","\n","\n","# 前処理を定義\n","transform_train = transforms.Compose([transforms.RandomCrop(32, padding=(4, 4, 4, 4), padding_mode='constant'),\n","                                transforms.RandomHorizontalFlip(p=0.5),\n","                                transforms.ToTensor(),\n","                                zca])\n","\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                zca])\n","\n","trainval_data.transform = transform_train\n","test_data.transform = transform\n","\n","batch_size = 64\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    train_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_valid = torch.utils.data.DataLoader(\n","    val_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_test = torch.utils.data.DataLoader(\n","    test_data,\n","    batch_size=batch_size,\n","    shuffle=False\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PADQiKNa2snb"},"source":["import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import torch.nn.functional as F\n","\n","rng = np.random.RandomState(1234)\n","random_state = 42\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","conv_net = # WRITE ME\n","\n","\n","def init_weights(m):  # Heの初期化\n","    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n","        torch.nn.init.kaiming_normal_(m.weight)\n","        m.bias.data.fill_(0.0)\n","\n","\n","conv_net.apply(init_weights)\n","\n","\n","n_epochs = 5\n","lr = 0.01\n","device = 'cuda'\n","\n","conv_net.to(device)\n","optimizer = # WRITE ME\n","loss_function = # WRITE ME"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nlOZuLu-328i"},"source":["for epoch in range(n_epochs):\n","    losses_train = []\n","    losses_valid = []\n","\n","    conv_net.train()\n","    n_train = 0\n","    acc_train = 0\n","    for x, t in dataloader_train:\n","        # WRITE ME\n","\n","        acc_train += (pred == t).float().sum().item()\n","        losses_train.append(loss.tolist())\n","\n","    conv_net.eval()\n","    n_val = 0\n","    acc_val = 0\n","    for x, t in dataloader_valid:\n","        # WRITE ME\n","\n","        acc_val += (pred == t).float().sum().item()\n","        losses_valid.append(loss.tolist())\n","\n","    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n","        epoch,\n","        np.mean(losses_train),\n","        acc_train/n_train,\n","        np.mean(losses_valid),\n","        acc_val/n_val\n","    ))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yq3scS5j4Rt2"},"source":["conv_net.eval()\n","\n","t_pred = []\n","for x in dataloader_test:\n","\n","    x = x.to(device)\n","\n","    # 順伝播\n","    y = conv_net.forward(x)\n","\n","    # モデルの出力を予測値のスカラーに変換\n","    pred = y.argmax(1).tolist()\n","\n","    t_pred.extend(pred)\n","\n","submission = pd.Series(t_pred, name='label')\n","submission.to_csv('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210513/submission_pred_sub.csv', header=True, index_label='id')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"73f8DjqTCoTL"},"source":[""],"execution_count":null,"outputs":[]}]}