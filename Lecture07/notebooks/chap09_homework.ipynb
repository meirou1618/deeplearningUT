{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"chap09_homework.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python395jvsc74a57bd0815b746931c540dd900bc689bff56968bb61769b1159081e25b8d44643e03281","display_name":"Python 3.9.5 64-bit"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"MUWcdth_khfN"},"source":["# 第7回講義 宿題"]},{"cell_type":"markdown","metadata":{"id":"gAjuP7I4lWyn"},"source":["## 課題. 変分オートエンコーダ（VAE）でFasionMNISTの画像を生成せよ\n"]},{"cell_type":"markdown","metadata":{"id":"qSHeI_utleEN"},"source":["### ルール\n","\n","- 訓練データはx_train、テストデータはx_testで与えられます。\n","- 下のセルで指定されているx_train以外の学習データは使わないでください。\n","- 提出コードの一番上の部分に工夫した事柄を数行でコメントアウトして書いてください（もっと書きたい人はたくさん書いても大丈夫です）。"]},{"cell_type":"markdown","metadata":{"id":"Cpiz19GRlZ_9"},"source":["### 目標値\n","\n","NLL（負の対数尤度） 235"]},{"cell_type":"markdown","metadata":{"id":"diuec-_YluI6"},"source":["### 提出方法\n","\n","- 2つのファイルを提出していただきます。\n","  - テストデータ (x_test) に対する予測ラベルをcsvファイル (ファイル名: submission_pred.csv) で提出してください。\n","  - それに対応するpythonのコードをsubmission_code.pyとして提出してください (%%writefileコマンドなどを利用してください)。"]},{"cell_type":"markdown","metadata":{"id":"hofSzJsVlvKp"},"source":["### 評価方法\n","\n","- 評価は生成画像のテストデータに対するNLL（負の対数尤度）で行います.$-\\sum_{i=1}^Dx_i\\log\\hat{x_i}+(1-x_i)\\log(1-\\hat{x_i})$\n","- 定時にNLLを計算しLeader Boardを更新します。\n","- 締切後のNLLを最終的な評価とします"]},{"cell_type":"markdown","metadata":{"id":"Cu4cmQtelx19"},"source":["### データの読み込み\n","\n","- この部分は修正しないでください"]},{"cell_type":"code","metadata":{"id":"EsLDDSUJkRx-"},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from torchvision import transforms\n","from tqdm import tqdm_notebook as tqdm\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","\n","# # 学習データ\n","# x_train = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210527/data/x_train.npy')\n","    \n","# # テストデータ\n","# x_test = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210527/data/x_test.npy')\n","#学習データ\n","x_train = np.load('/Users/明朗/workspace/deeplearningUT/Lecture07/data/x_train.npy')\n","    \n","#テストデータ\n","x_test = np.load('/Users/明朗/workspace/deeplearningUT/Lecture07/data/x_test.npy')\n","\n","\n","class dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_train):\n","        data = x_train.astype('float32')\n","        self.x_train = []\n","        for i in range(data.shape[0]):\n","            self.x_train.append(Image.fromarray(np.uint8(data[i])))\n","        self.transform = transforms.ToTensor()\n","\n","    def __len__(self):\n","        return len(self.x_train)\n","\n","    def __getitem__(self, idx):\n","        return self.transform(self.x_train[idx])\n","\n","trainval_data = dataset(x_train)\n","test_data = dataset(x_test)"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UrSpHDIWOfK_"},"source":["### VAEの実装\n"]},{"cell_type":"code","metadata":{"id":"sKAe0F36nSvU"},"source":["batch_size = 32\n","\n","val_size = 10000\n","train_size = len(trainval_data) - val_size\n","\n","train_data, val_data = torch.utils.data.random_split(trainval_data, [train_size, val_size])\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    train_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_valid = torch.utils.data.DataLoader(\n","    val_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_test = torch.utils.data.DataLoader(\n","    test_data,\n","    batch_size=batch_size,\n","    shuffle=False\n",")"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"PADQiKNa2snb"},"source":["'''\n","（工夫した事柄をこの部分に記入）\n","vaeの層をconvolutionで記述した．\n","beta-vaeも実装したが，そこまで性能の向上がみられなかったため，beta=1で学習した．\n","'''\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import torch.nn.functional as F\n","\n","device = 'cuda'\n","\n","\n","# torch.log(0)によるnanを防ぐ\n","def torch_log(x):\n","    return torch.log(torch.clamp(x, min=1e-10))\n","\n","\n","class VAE(nn.Module):\n","    def __init__(self, z_dim):\n","        super(VAE, self).__init__()\n","        self.dense_enc1 = nn.Sequential(\n","            nn.Conv2d(1, 32, 3, padding=1), #28 28 1 -> 28 28 32\n","            nn.BatchNorm2d(32)\n","        )\n","        self.dense_enc2 = nn.Sequential(\n","            nn.Conv2d(32, 32, 3, padding=1), # 28 28 32 -> 28 28 32\n","            nn.BatchNorm2d(32)\n","        )\n","        self.pool = nn.MaxPool2d(2)         #28 28 32 -> 14 14 32\n","        self.flat = nn.Flatten()\n","        self.dense_encmean = nn.Linear(28*28*32, z_dim)\n","        self.dense_encvar = nn.Linear(28*28*32, z_dim)\n","        self.dense_dec1 = nn.Linear(z_dim, 28*28*32)\n","        self.dense_dec2 = nn.Sequential(\n","            nn.Conv2d(32, 32, 3, padding=1),\n","            nn.BatchNorm2d(32)\n","        )\n","        self.dense_dec3 = nn.Sequential(\n","            nn.Conv2d(32, 1, 3, padding=1),\n","            nn.BatchNorm2d(1)\n","        )\n","\n","    def _encoder(self, x):\n","        x = F.relu(self.dense_enc1(x))\n","        x = F.relu(self.dense_enc2(x))\n","        #x = self.pool(x)\n","        x = self.flat(x)\n","        mean = self.dense_encmean(x)\n","        var = F.softplus(self.dense_encvar(x))\n","        return mean, var\n","\n","    def _sample_z(self, mean, var):\n","        epsilon = torch.randn(mean.shape).to(device)\n","        return mean + torch.sqrt(var) * epsilon\n","\n","    def _decoder(self, z):\n","        x = F.relu(self.dense_dec1(z))\n","        x = torch.reshape(x, (-1, 32, 28, 28))\n","        x = F.relu(self.dense_dec2(x))\n","        x = torch.sigmoid(self.dense_dec3(x))\n","        return x\n","\n","    def forward(self, x):\n","        mean, var = self._encoder(x)\n","        z = self._sample_z(mean, var)\n","        x = self._decoder(z)\n","        return x, z\n","\n","    def loss(self, x, beta=1):\n","        mean, var = self._encoder(x)\n","        # KL lossの計算\n","        KL = -0.5*torch.mean(torch.sum(1 + torch_log(var) - mean**2 - var, dim=1)) # WRITE ME\n","\n","        z = self._sample_z(mean, var)\n","        y = self._decoder(z)\n","\n","        # reconstruction lossの計算(今回はL=1)\n","        reconstruction = torch.mean(torch.sum(x*torch_log(y) + (1-x)*torch_log(1-y), dim=1)) # WRITE ME\n","\n","        return beta*KL, -reconstruction"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"nlOZuLu-328i"},"source":["z_dim = 10\n","n_epochs = 30\n","model = VAE(z_dim).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","for epoch in range(n_epochs):\n","    losses = []\n","    KL_losses = []\n","    reconstruction_losses = []\n","    model.train()\n","    for x in dataloader_train:\n","\n","        # WRITE ME\n","        x = x.to(device)\n","        model.zero_grad()\n","        y = model(x)\n","        KL_loss, reconstruction_loss = model.loss(x, 4)\n","        loss = KL_loss + reconstruction_loss\n","        loss.backward()\n","        optimizer.step()\n","\n","        losses.append(loss.cpu().detach().numpy())\n","        KL_losses.append(KL_loss.cpu().detach().numpy())\n","        reconstruction_losses.append(reconstruction_loss.cpu().detach().numpy())\n","\n","    losses_val = []\n","    model.eval()\n","    for x in dataloader_valid:\n","\n","        # WRITE ME\n","        x = x.to(device)\n","        y = model(x)\n","        KL_loss, reconstruction_loss = model.loss(x, 4)\n","        loss = KL_loss + reconstruction_loss\n","\n","        losses_val.append(loss.cpu().detach().numpy())\n","\n","    print('EPOCH:%d, Train Lower Bound:%lf, (%lf, %lf), Valid Lower Bound:%lf' %\n","          (epoch+1, np.average(losses), np.average(KL_losses), np.average(reconstruction_losses), np.average(losses_val)))"],"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["EPOCH:1, Train Lower Bound:4.223601, (3.694654, 0.528947), Valid Lower Bound:1.390561\n","EPOCH:2, Train Lower Bound:0.786652, (0.293958, 0.492694), Valid Lower Bound:0.630111\n","EPOCH:3, Train Lower Bound:0.570477, (0.079111, 0.491365), Valid Lower Bound:0.557828\n","EPOCH:4, Train Lower Bound:0.512392, (0.021280, 0.491112), Valid Lower Bound:0.500929\n","EPOCH:5, Train Lower Bound:0.496155, (0.005198, 0.490957), Valid Lower Bound:0.491953\n","EPOCH:6, Train Lower Bound:0.492869, (0.001937, 0.490932), Valid Lower Bound:0.491425\n","EPOCH:7, Train Lower Bound:0.492128, (0.001283, 0.490845), Valid Lower Bound:0.492238\n","EPOCH:8, Train Lower Bound:0.491770, (0.000985, 0.490786), Valid Lower Bound:0.490911\n","EPOCH:9, Train Lower Bound:0.491454, (0.000680, 0.490773), Valid Lower Bound:0.490280\n","EPOCH:10, Train Lower Bound:0.491022, (0.000277, 0.490745), Valid Lower Bound:0.490172\n","EPOCH:11, Train Lower Bound:0.490856, (0.000137, 0.490719), Valid Lower Bound:0.490034\n","EPOCH:12, Train Lower Bound:0.494906, (0.004208, 0.490698), Valid Lower Bound:0.489926\n","EPOCH:13, Train Lower Bound:0.490708, (0.000045, 0.490662), Valid Lower Bound:0.490232\n","EPOCH:14, Train Lower Bound:0.490732, (0.000063, 0.490669), Valid Lower Bound:0.489988\n","EPOCH:15, Train Lower Bound:0.490680, (0.000019, 0.490662), Valid Lower Bound:0.489963\n","EPOCH:16, Train Lower Bound:0.490647, (0.000025, 0.490622), Valid Lower Bound:0.490012\n","EPOCH:17, Train Lower Bound:0.490659, (0.000014, 0.490646), Valid Lower Bound:0.490024\n","EPOCH:18, Train Lower Bound:0.490609, (0.000009, 0.490600), Valid Lower Bound:0.489913\n","EPOCH:19, Train Lower Bound:0.490616, (0.000006, 0.490610), Valid Lower Bound:0.490021\n","EPOCH:20, Train Lower Bound:0.490624, (0.000002, 0.490622), Valid Lower Bound:0.489866\n","EPOCH:21, Train Lower Bound:0.490604, (0.000000, 0.490604), Valid Lower Bound:0.489887\n","EPOCH:22, Train Lower Bound:0.490617, (0.000000, 0.490616), Valid Lower Bound:0.489918\n","EPOCH:23, Train Lower Bound:0.490562, (0.000000, 0.490562), Valid Lower Bound:0.489830\n","EPOCH:24, Train Lower Bound:0.490678, (0.000088, 0.490590), Valid Lower Bound:0.489913\n","EPOCH:25, Train Lower Bound:0.490575, (0.000000, 0.490575), Valid Lower Bound:0.489836\n","EPOCH:26, Train Lower Bound:0.490591, (0.000000, 0.490591), Valid Lower Bound:0.489928\n","EPOCH:27, Train Lower Bound:0.490557, (0.000000, 0.490557), Valid Lower Bound:0.489870\n","EPOCH:28, Train Lower Bound:0.490565, (0.000000, 0.490565), Valid Lower Bound:0.489848\n","EPOCH:29, Train Lower Bound:0.490567, (0.000000, 0.490567), Valid Lower Bound:0.489908\n","EPOCH:30, Train Lower Bound:0.490574, (0.000000, 0.490574), Valid Lower Bound:0.489788\n"]}]},{"cell_type":"code","metadata":{"id":"Yq3scS5j4Rt2"},"source":["import csv\n","\n","sample_x = []\n","answer = []\n","model.eval()\n","for x in dataloader_test:\n","\n","    x = x.to(device)\n","\n","    y, _ = model(x)\n","\n","    y = y.tolist()\n","\n","    sample_x.extend(y)\n","\n","import os\n","os.makedirs('output', exist_ok=True)\n","\n","#with open('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210527/submission_pred.csv', 'w') as file:\n","with open('output/submission_pred.csv', 'w') as file:\n","    writer = csv.writer(file, lineterminator='\\n')\n","    writer.writerows(sample_x)\n","file.close()"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"73f8DjqTCoTL"},"source":[],"execution_count":null,"outputs":[]}]}