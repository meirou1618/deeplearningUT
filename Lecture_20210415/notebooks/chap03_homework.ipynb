{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python388jvsc74a57bd0514466fe9bdbb4465d0f72d486e68777ccb9801e0d08f857a8c5a4c505647bc4","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"chap03_homework.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"03FTy4lwzXiQ"},"source":["# 第3回講義 宿題"]},{"cell_type":"markdown","metadata":{"id":"JtnWqKVGzXiT"},"source":["## 課題\n","今Lessonで学んだことを元に、MNISTのファッション版 (Fashion MNIST、クラス数10) をソフトマックス回帰によって分類してみましょう。\n","\n","Fashion MNISTの詳細については以下のリンクを参考にしてください。\n","\n","Fashion MNIST: https://github.com/zalandoresearch/fashion-mnist"]},{"cell_type":"markdown","metadata":{"id":"zyD3F677zXiU"},"source":["### 目標値\n","Accuracy: 80%"]},{"cell_type":"markdown","metadata":{"id":"9pt9rMcxzXiU"},"source":["### ルール\n","- **下のセルで指定されている`x_train、y_train`以外の学習データは使わないでください。**\n","- **ソフトマックス回帰のアルゴリズム部分の実装はnumpyのみで行ってください** (sklearnやtensorflowなどは使用しないでください)。\n","    - データの前処理部分でsklearnの関数を使う (例えば `sklearn.model_selection.train_test_split`) のは問題ありません。"]},{"cell_type":"markdown","metadata":{"id":"2bq41q5SzXiV"},"source":["### 提出方法\n","- 2つのファイルを提出していただきます。\n","    1. テストデータ (`x_test`) に対する予測ラベルを`submission_pred.csv`として保存し、**Homeworkタブから`chap03`を選択して**提出してください。\n","    2. それに対応するpythonのコードを`submission_code.py`として保存し、**Homeworkタブから`chap03 (code)`を選択して**提出してください。\n","      \n","- なお、採点は1で行い、2はコードの確認用として利用します（成績優秀者はコード内容を公開させていただくかもしれません）。コードの内容を変更した場合は、**1と2の両方を提出し直してください**。"]},{"cell_type":"markdown","metadata":{"id":"KJKR8DMtzXiW"},"source":["### 評価方法\n","- 予測ラベルの`y_test`に対する精度 (Accuracy) で評価します。\n","- 定時に採点しLeader Boardを更新します。(採点スケジュールは別アナウンス）\n","- 締切後の点数を最終的な評価とします。"]},{"cell_type":"markdown","metadata":{"id":"r20uRSCUzXiX"},"source":["### データの読み込み (このセルは修正しないでください)"]},{"cell_type":"code","metadata":{"id":"OZodouZWzXiX"},"source":["import os\n","import sys\n","\n","import numpy as np\n","import pandas as pd\n","\n","sys.modules['tensorflow'] = None\n","\n","x_train = np.load('/home/sato.mizuki/deeplearningUT/Lecture_20210415/data/x_train.npy')\n","#drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210415/data/x_train.npy\n","def load_fashionmnist():\n","    # 学習データ\n","    x_train = np.load('/home/sato.mizuki/deeplearningUT/Lecture_20210415/data/x_train.npy')\n","    y_train = np.load('/home/sato.mizuki/deeplearningUT/Lecture_20210415/data/y_train.npy')\n","    \n","    # テストデータ\n","    x_test = np.load('/home/sato.mizuki/deeplearningUT/Lecture_20210415/data/x_test.npy')\n","    \n","    x_train = x_train.reshape(-1, 784).astype('float32') / 255\n","    y_train = np.eye(10)[y_train.astype('int32')]\n","    x_test = x_test.reshape(-1, 784).astype('float32') / 255\n","    \n","    return x_train, y_train, x_test"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mHynK8xAzXid"},"source":["### ソフトマックス回帰の実装"]},{"cell_type":"code","metadata":{"id":"gU9E1ppuzXie"},"source":["\n","x_train, y_train, x_test = load_fashionmnist()\n","\n","from sklearn.utils import shuffle\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","\n","def softmax(x):\n","    x -= x.max(axis=1, keepdims=True)\n","    x_exp = np.exp(x)\n","    return x_exp / np.sum(x_exp, axis=1, keepdims=True)\n","    # WRITE ME\n","\n","# weights\n","W = np.random.normal(0, 1/784, (784, 10)).astype('float32')\n","#np.random.uniform(low=-0.08, high=0.08, size=(784, 10)).astype('float32')# WRITE ME\n","b = np.zeros(shape=(10,)).astype('float32')# WRITE ME\n","\n","# 学習データと検証データに分割\n","x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1,random_state=1)\n","\n","# logの中身が0になるのを防ぐ\n","def np_log(x):\n","    return np.log(np.clip(a=x, a_min=1e-10, a_max=1e+10))\n","\n","def train(x, t, eps=1.0):\n","    global W, b\n","    batch_size = x.shape[0]\n","\n","    #prediction\n","    y_hat = softmax(np.matmul(x, W)+b)\n","\n","    #evaluation\n","    cost = (-t * np_log(y_hat)).sum(axis=1).mean()\n","    delta = y_hat - t\n","\n","    #param\n","    dW = np.matmul(x.T, delta)\n","    db = np.matmul(np.ones(batch_size), delta)\n","\n","    W -= eps*dW\n","    b -= eps*db\n","\n","    return cost\n","    \n","    # WRITE ME\n","\n","def valid(x, t):\n","    y_hat = softmax(np.matmul(x, W) + b)\n","    cost = (-t*np_log(y_hat)).sum(axis=1).mean()\n","\n","    return cost, y_hat\n","\n","    # WRITE ME\n","eps = 2.0\n","for epoch in range(5000):\n","    # オンライン学習\n","    pre_accuracy = 0\n","    x_train, y_train = shuffle(x_train, y_train, random_state=0)\n","    cost = train(x_train, y_train, eps)\n","    cost, y_pred = valid(x_valid, y_valid)\n","    accuracy = accuracy_score(y_valid.argmax(axis=1), y_pred.argmax(axis=1))\n","    if epoch % 10 == 9 or epoch == 0:\n","        print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n","            epoch+1,\n","            cost,\n","            accuracy\n","        ))\n","\n","    if accuracy > 0.7:\n","        eps = 0.9\n","    elif accuracy >0.75:\n","        eps = 0.8\n","    elif accuracy >0.8:\n","        eps = 0.2\n","    else:\n","        eps = 1.0\n","\n","    if accuracy > 0.85:\n","        print(accuracy)\n","        break\n","    # WRITE ME\n","\n","y_pred = softmax(np.matmul(x_test, W) + b)\n","# WRITE ME\n","\"\"\"\n","submission = pd.Series(y_pred, name='label')\n","submission.to_csv('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210415/submission_pred.csv', header=True, index_label='id')\n","\"\"\""],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["EPOCH: 1, Valid Cost: 16.459, Valid Accuracy: 0.285\n","EPOCH: 10, Valid Cost: 10.703, Valid Accuracy: 0.535\n","EPOCH: 20, Valid Cost: 8.746, Valid Accuracy: 0.620\n","EPOCH: 30, Valid Cost: 7.987, Valid Accuracy: 0.653\n","EPOCH: 40, Valid Cost: 7.691, Valid Accuracy: 0.666\n","EPOCH: 50, Valid Cost: 6.129, Valid Accuracy: 0.734\n","EPOCH: 60, Valid Cost: 5.657, Valid Accuracy: 0.754\n","EPOCH: 70, Valid Cost: 7.169, Valid Accuracy: 0.689\n","EPOCH: 80, Valid Cost: 6.159, Valid Accuracy: 0.733\n","EPOCH: 90, Valid Cost: 6.547, Valid Accuracy: 0.716\n","EPOCH: 100, Valid Cost: 6.397, Valid Accuracy: 0.722\n","EPOCH: 110, Valid Cost: 5.895, Valid Accuracy: 0.744\n","EPOCH: 120, Valid Cost: 6.885, Valid Accuracy: 0.701\n","EPOCH: 130, Valid Cost: 5.446, Valid Accuracy: 0.763\n","EPOCH: 140, Valid Cost: 5.288, Valid Accuracy: 0.770\n","EPOCH: 150, Valid Cost: 5.637, Valid Accuracy: 0.755\n","EPOCH: 160, Valid Cost: 4.482, Valid Accuracy: 0.805\n","EPOCH: 170, Valid Cost: 5.787, Valid Accuracy: 0.749\n","EPOCH: 180, Valid Cost: 6.662, Valid Accuracy: 0.711\n","EPOCH: 190, Valid Cost: 6.351, Valid Accuracy: 0.724\n","EPOCH: 200, Valid Cost: 6.977, Valid Accuracy: 0.697\n","EPOCH: 210, Valid Cost: 4.229, Valid Accuracy: 0.816\n","EPOCH: 220, Valid Cost: 5.457, Valid Accuracy: 0.763\n","EPOCH: 230, Valid Cost: 7.599, Valid Accuracy: 0.670\n","EPOCH: 240, Valid Cost: 4.795, Valid Accuracy: 0.792\n","EPOCH: 250, Valid Cost: 4.405, Valid Accuracy: 0.809\n","EPOCH: 260, Valid Cost: 5.334, Valid Accuracy: 0.768\n","EPOCH: 270, Valid Cost: 6.697, Valid Accuracy: 0.709\n","EPOCH: 280, Valid Cost: 7.027, Valid Accuracy: 0.695\n","EPOCH: 290, Valid Cost: 6.474, Valid Accuracy: 0.719\n","EPOCH: 300, Valid Cost: 4.628, Valid Accuracy: 0.799\n","EPOCH: 310, Valid Cost: 7.349, Valid Accuracy: 0.681\n","EPOCH: 320, Valid Cost: 6.020, Valid Accuracy: 0.739\n","EPOCH: 330, Valid Cost: 5.795, Valid Accuracy: 0.748\n","EPOCH: 340, Valid Cost: 5.119, Valid Accuracy: 0.778\n","EPOCH: 350, Valid Cost: 4.271, Valid Accuracy: 0.815\n","EPOCH: 360, Valid Cost: 5.403, Valid Accuracy: 0.765\n","EPOCH: 370, Valid Cost: 5.772, Valid Accuracy: 0.749\n","EPOCH: 380, Valid Cost: 5.591, Valid Accuracy: 0.757\n","EPOCH: 390, Valid Cost: 5.035, Valid Accuracy: 0.781\n","EPOCH: 400, Valid Cost: 5.242, Valid Accuracy: 0.772\n","EPOCH: 410, Valid Cost: 4.960, Valid Accuracy: 0.784\n","EPOCH: 420, Valid Cost: 5.077, Valid Accuracy: 0.779\n","EPOCH: 430, Valid Cost: 4.383, Valid Accuracy: 0.810\n","EPOCH: 440, Valid Cost: 5.361, Valid Accuracy: 0.767\n","EPOCH: 450, Valid Cost: 5.879, Valid Accuracy: 0.745\n","EPOCH: 460, Valid Cost: 4.701, Valid Accuracy: 0.796\n","EPOCH: 470, Valid Cost: 5.416, Valid Accuracy: 0.765\n","EPOCH: 480, Valid Cost: 5.645, Valid Accuracy: 0.755\n","EPOCH: 490, Valid Cost: 4.252, Valid Accuracy: 0.815\n","EPOCH: 500, Valid Cost: 6.681, Valid Accuracy: 0.710\n","EPOCH: 510, Valid Cost: 5.515, Valid Accuracy: 0.760\n","EPOCH: 520, Valid Cost: 5.212, Valid Accuracy: 0.774\n","EPOCH: 530, Valid Cost: 5.875, Valid Accuracy: 0.745\n","EPOCH: 540, Valid Cost: 5.918, Valid Accuracy: 0.743\n","EPOCH: 550, Valid Cost: 4.797, Valid Accuracy: 0.792\n","EPOCH: 560, Valid Cost: 6.163, Valid Accuracy: 0.732\n","EPOCH: 570, Valid Cost: 4.928, Valid Accuracy: 0.786\n","EPOCH: 580, Valid Cost: 5.753, Valid Accuracy: 0.750\n","EPOCH: 590, Valid Cost: 4.816, Valid Accuracy: 0.791\n","EPOCH: 600, Valid Cost: 6.209, Valid Accuracy: 0.730\n","EPOCH: 610, Valid Cost: 5.369, Valid Accuracy: 0.767\n","EPOCH: 620, Valid Cost: 5.043, Valid Accuracy: 0.781\n","EPOCH: 630, Valid Cost: 6.440, Valid Accuracy: 0.720\n","EPOCH: 640, Valid Cost: 4.276, Valid Accuracy: 0.814\n","EPOCH: 650, Valid Cost: 5.093, Valid Accuracy: 0.779\n","EPOCH: 660, Valid Cost: 4.452, Valid Accuracy: 0.806\n","EPOCH: 670, Valid Cost: 4.452, Valid Accuracy: 0.807\n","EPOCH: 680, Valid Cost: 5.691, Valid Accuracy: 0.753\n","EPOCH: 690, Valid Cost: 5.553, Valid Accuracy: 0.759\n","EPOCH: 700, Valid Cost: 5.300, Valid Accuracy: 0.770\n","EPOCH: 710, Valid Cost: 5.261, Valid Accuracy: 0.771\n","EPOCH: 720, Valid Cost: 4.375, Valid Accuracy: 0.810\n","EPOCH: 730, Valid Cost: 5.373, Valid Accuracy: 0.767\n","EPOCH: 740, Valid Cost: 6.060, Valid Accuracy: 0.737\n","EPOCH: 750, Valid Cost: 7.221, Valid Accuracy: 0.686\n","EPOCH: 760, Valid Cost: 4.544, Valid Accuracy: 0.803\n","EPOCH: 770, Valid Cost: 5.676, Valid Accuracy: 0.753\n","EPOCH: 780, Valid Cost: 4.294, Valid Accuracy: 0.814\n","EPOCH: 790, Valid Cost: 5.415, Valid Accuracy: 0.765\n","EPOCH: 800, Valid Cost: 5.808, Valid Accuracy: 0.748\n","EPOCH: 810, Valid Cost: 5.119, Valid Accuracy: 0.778\n","EPOCH: 820, Valid Cost: 4.724, Valid Accuracy: 0.795\n","EPOCH: 830, Valid Cost: 4.444, Valid Accuracy: 0.807\n","EPOCH: 840, Valid Cost: 4.229, Valid Accuracy: 0.816\n","EPOCH: 850, Valid Cost: 8.562, Valid Accuracy: 0.628\n","EPOCH: 860, Valid Cost: 5.411, Valid Accuracy: 0.765\n","EPOCH: 870, Valid Cost: 4.452, Valid Accuracy: 0.807\n","EPOCH: 880, Valid Cost: 4.874, Valid Accuracy: 0.788\n","EPOCH: 890, Valid Cost: 4.590, Valid Accuracy: 0.801\n","EPOCH: 900, Valid Cost: 5.864, Valid Accuracy: 0.745\n","EPOCH: 910, Valid Cost: 5.488, Valid Accuracy: 0.761\n","EPOCH: 920, Valid Cost: 4.360, Valid Accuracy: 0.811\n","EPOCH: 930, Valid Cost: 5.027, Valid Accuracy: 0.782\n","EPOCH: 940, Valid Cost: 4.540, Valid Accuracy: 0.803\n","EPOCH: 950, Valid Cost: 5.580, Valid Accuracy: 0.758\n","EPOCH: 960, Valid Cost: 4.325, Valid Accuracy: 0.812\n","EPOCH: 970, Valid Cost: 5.607, Valid Accuracy: 0.756\n","EPOCH: 980, Valid Cost: 4.775, Valid Accuracy: 0.792\n","EPOCH: 990, Valid Cost: 3.738, Valid Accuracy: 0.838\n","EPOCH: 1000, Valid Cost: 4.010, Valid Accuracy: 0.826\n","EPOCH: 1010, Valid Cost: 5.162, Valid Accuracy: 0.776\n","EPOCH: 1020, Valid Cost: 4.356, Valid Accuracy: 0.811\n","EPOCH: 1030, Valid Cost: 7.852, Valid Accuracy: 0.659\n","EPOCH: 1040, Valid Cost: 5.008, Valid Accuracy: 0.782\n","EPOCH: 1050, Valid Cost: 4.444, Valid Accuracy: 0.807\n","EPOCH: 1060, Valid Cost: 4.256, Valid Accuracy: 0.815\n","EPOCH: 1070, Valid Cost: 3.761, Valid Accuracy: 0.837\n","EPOCH: 1080, Valid Cost: 4.701, Valid Accuracy: 0.796\n","EPOCH: 1090, Valid Cost: 5.449, Valid Accuracy: 0.763\n","EPOCH: 1100, Valid Cost: 4.383, Valid Accuracy: 0.810\n","EPOCH: 1110, Valid Cost: 5.097, Valid Accuracy: 0.778\n","EPOCH: 1120, Valid Cost: 4.432, Valid Accuracy: 0.807\n","EPOCH: 1130, Valid Cost: 5.396, Valid Accuracy: 0.766\n","EPOCH: 1140, Valid Cost: 5.893, Valid Accuracy: 0.744\n","EPOCH: 1150, Valid Cost: 4.750, Valid Accuracy: 0.794\n","EPOCH: 1160, Valid Cost: 4.951, Valid Accuracy: 0.785\n","EPOCH: 1170, Valid Cost: 4.916, Valid Accuracy: 0.786\n","EPOCH: 1180, Valid Cost: 5.983, Valid Accuracy: 0.740\n","EPOCH: 1190, Valid Cost: 5.776, Valid Accuracy: 0.749\n","EPOCH: 1200, Valid Cost: 5.879, Valid Accuracy: 0.745\n","EPOCH: 1210, Valid Cost: 4.682, Valid Accuracy: 0.797\n","EPOCH: 1220, Valid Cost: 4.264, Valid Accuracy: 0.815\n","EPOCH: 1230, Valid Cost: 5.135, Valid Accuracy: 0.777\n","EPOCH: 1240, Valid Cost: 6.440, Valid Accuracy: 0.720\n","EPOCH: 1250, Valid Cost: 5.971, Valid Accuracy: 0.741\n","EPOCH: 1260, Valid Cost: 4.306, Valid Accuracy: 0.813\n","EPOCH: 1270, Valid Cost: 4.974, Valid Accuracy: 0.784\n","EPOCH: 1280, Valid Cost: 6.086, Valid Accuracy: 0.736\n","EPOCH: 1290, Valid Cost: 6.067, Valid Accuracy: 0.737\n","EPOCH: 1300, Valid Cost: 4.437, Valid Accuracy: 0.807\n","EPOCH: 1310, Valid Cost: 4.679, Valid Accuracy: 0.797\n","EPOCH: 1320, Valid Cost: 5.983, Valid Accuracy: 0.740\n","EPOCH: 1330, Valid Cost: 4.287, Valid Accuracy: 0.814\n","EPOCH: 1340, Valid Cost: 5.496, Valid Accuracy: 0.761\n","EPOCH: 1350, Valid Cost: 6.397, Valid Accuracy: 0.722\n","EPOCH: 1360, Valid Cost: 4.221, Valid Accuracy: 0.817\n","EPOCH: 1370, Valid Cost: 4.390, Valid Accuracy: 0.809\n","EPOCH: 1380, Valid Cost: 5.204, Valid Accuracy: 0.774\n","EPOCH: 1390, Valid Cost: 4.843, Valid Accuracy: 0.790\n","EPOCH: 1400, Valid Cost: 5.054, Valid Accuracy: 0.780\n","EPOCH: 1410, Valid Cost: 4.087, Valid Accuracy: 0.823\n","EPOCH: 1420, Valid Cost: 4.429, Valid Accuracy: 0.808\n","EPOCH: 1430, Valid Cost: 5.062, Valid Accuracy: 0.780\n","EPOCH: 1440, Valid Cost: 5.676, Valid Accuracy: 0.753\n","EPOCH: 1450, Valid Cost: 6.600, Valid Accuracy: 0.713\n","EPOCH: 1460, Valid Cost: 6.071, Valid Accuracy: 0.736\n","EPOCH: 1470, Valid Cost: 4.252, Valid Accuracy: 0.815\n","EPOCH: 1480, Valid Cost: 4.536, Valid Accuracy: 0.803\n","EPOCH: 1490, Valid Cost: 4.551, Valid Accuracy: 0.802\n","EPOCH: 1500, Valid Cost: 4.160, Valid Accuracy: 0.819\n","EPOCH: 1510, Valid Cost: 4.874, Valid Accuracy: 0.788\n","EPOCH: 1520, Valid Cost: 5.327, Valid Accuracy: 0.769\n","EPOCH: 1530, Valid Cost: 5.653, Valid Accuracy: 0.754\n","EPOCH: 1540, Valid Cost: 5.273, Valid Accuracy: 0.771\n","EPOCH: 1550, Valid Cost: 3.822, Valid Accuracy: 0.834\n","EPOCH: 1560, Valid Cost: 4.832, Valid Accuracy: 0.790\n","EPOCH: 1570, Valid Cost: 6.152, Valid Accuracy: 0.733\n","EPOCH: 1580, Valid Cost: 6.025, Valid Accuracy: 0.738\n","EPOCH: 1590, Valid Cost: 4.311, Valid Accuracy: 0.813\n","EPOCH: 1600, Valid Cost: 5.480, Valid Accuracy: 0.762\n","EPOCH: 1610, Valid Cost: 4.901, Valid Accuracy: 0.787\n","EPOCH: 1620, Valid Cost: 4.459, Valid Accuracy: 0.806\n","EPOCH: 1630, Valid Cost: 4.375, Valid Accuracy: 0.810\n","EPOCH: 1640, Valid Cost: 4.931, Valid Accuracy: 0.786\n","EPOCH: 1650, Valid Cost: 6.412, Valid Accuracy: 0.722\n","EPOCH: 1660, Valid Cost: 4.125, Valid Accuracy: 0.821\n","EPOCH: 1670, Valid Cost: 5.004, Valid Accuracy: 0.783\n","EPOCH: 1680, Valid Cost: 5.162, Valid Accuracy: 0.776\n","EPOCH: 1690, Valid Cost: 4.855, Valid Accuracy: 0.789\n","EPOCH: 1700, Valid Cost: 4.786, Valid Accuracy: 0.792\n","EPOCH: 1710, Valid Cost: 4.544, Valid Accuracy: 0.803\n","EPOCH: 1720, Valid Cost: 4.436, Valid Accuracy: 0.807\n","EPOCH: 1730, Valid Cost: 4.091, Valid Accuracy: 0.822\n","EPOCH: 1740, Valid Cost: 4.260, Valid Accuracy: 0.815\n","EPOCH: 1750, Valid Cost: 5.630, Valid Accuracy: 0.755\n","EPOCH: 1760, Valid Cost: 4.786, Valid Accuracy: 0.792\n","EPOCH: 1770, Valid Cost: 4.663, Valid Accuracy: 0.797\n","EPOCH: 1780, Valid Cost: 5.384, Valid Accuracy: 0.766\n","EPOCH: 1790, Valid Cost: 4.743, Valid Accuracy: 0.794\n","EPOCH: 1800, Valid Cost: 4.010, Valid Accuracy: 0.826\n","EPOCH: 1810, Valid Cost: 4.396, Valid Accuracy: 0.809\n","EPOCH: 1820, Valid Cost: 3.788, Valid Accuracy: 0.836\n","EPOCH: 1830, Valid Cost: 4.578, Valid Accuracy: 0.801\n","EPOCH: 1840, Valid Cost: 5.549, Valid Accuracy: 0.759\n","EPOCH: 1850, Valid Cost: 4.329, Valid Accuracy: 0.812\n","EPOCH: 1860, Valid Cost: 5.756, Valid Accuracy: 0.750\n","EPOCH: 1870, Valid Cost: 4.812, Valid Accuracy: 0.791\n","EPOCH: 1880, Valid Cost: 4.659, Valid Accuracy: 0.798\n","EPOCH: 1890, Valid Cost: 4.106, Valid Accuracy: 0.822\n","EPOCH: 1900, Valid Cost: 6.152, Valid Accuracy: 0.733\n","EPOCH: 1910, Valid Cost: 5.503, Valid Accuracy: 0.761\n","EPOCH: 1920, Valid Cost: 4.870, Valid Accuracy: 0.788\n","EPOCH: 1930, Valid Cost: 4.367, Valid Accuracy: 0.810\n","EPOCH: 1940, Valid Cost: 5.668, Valid Accuracy: 0.754\n","EPOCH: 1950, Valid Cost: 4.068, Valid Accuracy: 0.823\n","EPOCH: 1960, Valid Cost: 6.006, Valid Accuracy: 0.739\n","EPOCH: 1970, Valid Cost: 4.528, Valid Accuracy: 0.803\n","EPOCH: 1980, Valid Cost: 5.254, Valid Accuracy: 0.772\n","EPOCH: 1990, Valid Cost: 4.340, Valid Accuracy: 0.811\n","EPOCH: 2000, Valid Cost: 4.409, Valid Accuracy: 0.808\n","EPOCH: 2010, Valid Cost: 6.002, Valid Accuracy: 0.739\n","EPOCH: 2020, Valid Cost: 4.914, Valid Accuracy: 0.786\n","EPOCH: 2030, Valid Cost: 4.660, Valid Accuracy: 0.797\n","EPOCH: 2040, Valid Cost: 3.496, Valid Accuracy: 0.848\n","EPOCH: 2050, Valid Cost: 5.806, Valid Accuracy: 0.748\n","EPOCH: 2060, Valid Cost: 5.123, Valid Accuracy: 0.777\n","EPOCH: 2070, Valid Cost: 5.553, Valid Accuracy: 0.759\n","EPOCH: 2080, Valid Cost: 4.363, Valid Accuracy: 0.810\n","EPOCH: 2090, Valid Cost: 4.271, Valid Accuracy: 0.815\n","EPOCH: 2100, Valid Cost: 4.275, Valid Accuracy: 0.814\n","EPOCH: 2110, Valid Cost: 4.145, Valid Accuracy: 0.820\n","EPOCH: 2120, Valid Cost: 5.549, Valid Accuracy: 0.759\n","EPOCH: 2130, Valid Cost: 6.174, Valid Accuracy: 0.732\n","EPOCH: 2140, Valid Cost: 4.943, Valid Accuracy: 0.785\n","EPOCH: 2150, Valid Cost: 4.225, Valid Accuracy: 0.817\n","EPOCH: 2160, Valid Cost: 5.288, Valid Accuracy: 0.770\n","EPOCH: 2170, Valid Cost: 4.609, Valid Accuracy: 0.800\n","EPOCH: 2180, Valid Cost: 6.157, Valid Accuracy: 0.733\n","EPOCH: 2190, Valid Cost: 4.417, Valid Accuracy: 0.808\n","EPOCH: 2200, Valid Cost: 5.231, Valid Accuracy: 0.773\n","EPOCH: 2210, Valid Cost: 4.574, Valid Accuracy: 0.801\n","EPOCH: 2220, Valid Cost: 6.401, Valid Accuracy: 0.722\n","EPOCH: 2230, Valid Cost: 4.287, Valid Accuracy: 0.814\n","EPOCH: 2240, Valid Cost: 5.576, Valid Accuracy: 0.758\n","EPOCH: 2250, Valid Cost: 6.689, Valid Accuracy: 0.710\n","EPOCH: 2260, Valid Cost: 4.805, Valid Accuracy: 0.791\n","EPOCH: 2270, Valid Cost: 3.581, Valid Accuracy: 0.845\n","EPOCH: 2280, Valid Cost: 4.931, Valid Accuracy: 0.786\n","EPOCH: 2290, Valid Cost: 4.597, Valid Accuracy: 0.800\n","EPOCH: 2300, Valid Cost: 5.292, Valid Accuracy: 0.770\n","EPOCH: 2310, Valid Cost: 4.774, Valid Accuracy: 0.793\n","EPOCH: 2320, Valid Cost: 4.363, Valid Accuracy: 0.810\n","EPOCH: 2330, Valid Cost: 5.181, Valid Accuracy: 0.775\n","EPOCH: 2340, Valid Cost: 4.125, Valid Accuracy: 0.821\n","EPOCH: 2350, Valid Cost: 6.236, Valid Accuracy: 0.729\n","EPOCH: 2360, Valid Cost: 5.165, Valid Accuracy: 0.776\n","EPOCH: 2370, Valid Cost: 4.908, Valid Accuracy: 0.787\n","EPOCH: 2380, Valid Cost: 4.037, Valid Accuracy: 0.825\n","EPOCH: 2390, Valid Cost: 5.112, Valid Accuracy: 0.778\n","EPOCH: 2400, Valid Cost: 4.966, Valid Accuracy: 0.784\n","EPOCH: 2410, Valid Cost: 4.874, Valid Accuracy: 0.788\n","EPOCH: 2420, Valid Cost: 4.479, Valid Accuracy: 0.805\n","EPOCH: 2430, Valid Cost: 5.837, Valid Accuracy: 0.747\n","EPOCH: 2440, Valid Cost: 4.540, Valid Accuracy: 0.803\n","EPOCH: 2450, Valid Cost: 4.409, Valid Accuracy: 0.808\n","EPOCH: 2460, Valid Cost: 6.701, Valid Accuracy: 0.709\n","EPOCH: 2470, Valid Cost: 4.881, Valid Accuracy: 0.788\n","EPOCH: 2480, Valid Cost: 4.302, Valid Accuracy: 0.813\n","EPOCH: 2490, Valid Cost: 3.515, Valid Accuracy: 0.847\n","EPOCH: 2500, Valid Cost: 4.682, Valid Accuracy: 0.797\n","EPOCH: 2510, Valid Cost: 4.302, Valid Accuracy: 0.813\n","EPOCH: 2520, Valid Cost: 5.261, Valid Accuracy: 0.771\n","EPOCH: 2530, Valid Cost: 4.824, Valid Accuracy: 0.790\n","EPOCH: 2540, Valid Cost: 5.111, Valid Accuracy: 0.778\n","EPOCH: 2550, Valid Cost: 4.713, Valid Accuracy: 0.795\n","EPOCH: 2560, Valid Cost: 5.600, Valid Accuracy: 0.757\n","EPOCH: 2570, Valid Cost: 4.551, Valid Accuracy: 0.802\n","EPOCH: 2580, Valid Cost: 4.607, Valid Accuracy: 0.800\n","EPOCH: 2590, Valid Cost: 4.722, Valid Accuracy: 0.795\n","EPOCH: 2600, Valid Cost: 4.743, Valid Accuracy: 0.794\n","EPOCH: 2610, Valid Cost: 4.747, Valid Accuracy: 0.794\n","EPOCH: 2620, Valid Cost: 4.072, Valid Accuracy: 0.823\n","EPOCH: 2630, Valid Cost: 6.040, Valid Accuracy: 0.738\n","EPOCH: 2640, Valid Cost: 4.417, Valid Accuracy: 0.808\n","EPOCH: 2650, Valid Cost: 4.977, Valid Accuracy: 0.784\n","EPOCH: 2660, Valid Cost: 4.083, Valid Accuracy: 0.823\n","EPOCH: 2670, Valid Cost: 5.223, Valid Accuracy: 0.773\n","EPOCH: 2680, Valid Cost: 4.759, Valid Accuracy: 0.793\n","EPOCH: 2690, Valid Cost: 4.333, Valid Accuracy: 0.812\n","EPOCH: 2700, Valid Cost: 4.279, Valid Accuracy: 0.814\n","EPOCH: 2710, Valid Cost: 4.475, Valid Accuracy: 0.806\n","EPOCH: 2720, Valid Cost: 4.191, Valid Accuracy: 0.818\n","EPOCH: 2730, Valid Cost: 5.213, Valid Accuracy: 0.773\n","EPOCH: 2740, Valid Cost: 9.475, Valid Accuracy: 0.589\n","EPOCH: 2750, Valid Cost: 4.295, Valid Accuracy: 0.813\n","EPOCH: 2760, Valid Cost: 4.947, Valid Accuracy: 0.785\n","EPOCH: 2770, Valid Cost: 4.789, Valid Accuracy: 0.792\n","EPOCH: 2780, Valid Cost: 4.110, Valid Accuracy: 0.822\n","EPOCH: 2790, Valid Cost: 3.888, Valid Accuracy: 0.831\n","0.8501666666666666\n"]},{"output_type":"execute_result","data":{"text/plain":["\"\\nsubmission = pd.Series(y_pred, name='label')\\nsubmission.to_csv('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210415/submission_pred.csv', header=True, index_label='id')\\n\""]},"metadata":{},"execution_count":4}]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}