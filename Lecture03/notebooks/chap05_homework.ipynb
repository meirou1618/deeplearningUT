{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"chap05_homework.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MUWcdth_khfN"},"source":["# 第3回講義 宿題"]},{"cell_type":"markdown","metadata":{"id":"gAjuP7I4lWyn"},"source":["## 課題\n","\n","今Lessonで学んだことを元に、MNISTのファッション版 (Fashion MNIST、クラス数10) を多層パーセプトロンによって分類してみましょう。\n","\n","Fashion MNISTの詳細については以下のリンクを参考にしてください。\n","\n","Fashion MNIST: https://github.com/zalandoresearch/fashion-mnist"]},{"cell_type":"markdown","metadata":{"id":"Cpiz19GRlZ_9"},"source":["### 目標値\n","\n","Accuracy 85%"]},{"cell_type":"markdown","metadata":{"id":"qSHeI_utleEN"},"source":["### ルール\n","\n","- 訓練データはx_train、 t_train、テストデータはx_testで与えられます。\n","- 予測ラベルは one_hot表現ではなく0~9のクラスラベル で表してください。\n","- **下のセルで指定されているx_train、t_train以外の学習データは使わないでください。**\n","- Pytorchを利用して構いません。\n","- ただし、**torch.nn.Conv2dのような高レベルのAPIは使用しないで下さい。**具体的には、nn.Parameter, nn.Module, nn.Sequential以外のnn系のAPIです。\n","- torchvision等で既に実装されているモデルも使用しないで下さい。"]},{"cell_type":"markdown","metadata":{"id":"diuec-_YluI6"},"source":["### 提出方法\n","\n","- 2つのファイルを提出していただきます。\n","  - テストデータ (x_test) に対する予測ラベルをcsvファイル (ファイル名: submission_pred.csv) で提出してください。\n","  - それに対応するpythonのコードをsubmission_code.pyとして提出してください (%%writefileコマンドなどを利用してください)。"]},{"cell_type":"markdown","metadata":{"id":"hofSzJsVlvKp"},"source":["### 評価方法\n","\n","- 予測ラベルのt_testに対する精度 (Accuracy) で評価します。\n","- 定時に採点しLeader Boardを更新します。(採点スケジュールは別アナウンス）\n","- 締切後の点数を最終的な評価とします。"]},{"cell_type":"markdown","metadata":{"id":"Cu4cmQtelx19"},"source":["### データの読み込み\n","\n","- この部分は修正しないでください"]},{"cell_type":"code","metadata":{"id":"EsLDDSUJkRx-"},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import inspect\n"," \n","nn_except = [\"Module\", \"Parameter\", \"Sequential\"]\n","for m in inspect.getmembers(nn):\n","    if not m[0] in nn_except and m[0][0:2] != \"__\":\n","        delattr(nn, m[0]) \n","\n","#学習データ\n","x_train = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210422/data/x_train.npy')\n","t_train = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210422/data/y_train.npy')\n","    \n","#テストデータ\n","x_test = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210422/data/x_test.npy')\n","\n","class train_dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_train, t_train):\n","        self.x_train = x_train.reshape(-1, 784).astype('float32') / 255\n","        self.t_train = t_train\n","\n","    def __len__(self):\n","        return self.x_train.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.x_train[idx], dtype=torch.float), torch.tensor(t_train[idx], dtype=torch.long)\n","\n","class test_dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_test):\n","        self.x_test = x_test.reshape(-1, 784).astype('float32') / 255\n","\n","    def __len__(self):\n","        return self.x_test.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.x_test[idx], dtype=torch.float)\n","\n","trainval_data = train_dataset(x_train, t_train)\n","test_data = test_dataset(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UrSpHDIWOfK_"},"source":["### 多層パーセプトロンの実装"]},{"cell_type":"code","metadata":{"id":"sKAe0F36nSvU"},"source":["batch_size = 32\n","\n","val_size = 10000\n","train_size = len(trainval_data) - val_size\n","\n","train_data, val_data = torch.utils.data.random_split(trainval_data, [train_size, val_size])\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    train_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_valid = torch.utils.data.DataLoader(\n","    val_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_test = torch.utils.data.DataLoader(\n","    test_data,\n","    batch_size=batch_size,\n","    shuffle=False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PADQiKNa2snb"},"source":["rng = np.random.RandomState(1234)\n","random_state = 42\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","def relu(x):\n","    # WRITE ME\n","\n","\n","def softmax(x):\n","    # WRITE ME\n","\n","\n","class Dense(nn.Module):  # nn.Moduleを継承する\n","    # WRITE ME\n","\n","\n","class MLP(nn.Module):  # nn.Moduleを継承する\n","    # WRITE ME\n","\n","in_dim = 784\n","hid_dim = 200\n","out_dim = 10\n","lr = 0.001\n","n_epochs = 10\n","\n","\n","mlp = # WRITE ME\n","\n","optimizer = # WRITE ME"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nlOZuLu-328i"},"source":["for epoch in range(n_epochs):\n","    losses_train = []\n","    losses_valid = []\n","    train_num = 0\n","    train_true_num = 0\n","    valid_num = 0\n","    valid_true_num = 0\n","\n","    mlp.train()  # 訓練時には勾配を計算するtrainモードにする\n","    for x, t in dataloader_train:\n","        # WRITE ME\n","\n","        losses_train.append(loss.tolist())\n","\n","        acc = torch.where(t - pred.to(\"cpu\") == 0, torch.ones_like(t), torch.zeros_like(t))\n","        train_num += acc.size()[0]\n","        train_true_num += acc.sum().item()\n","\n","    mlp.eval()  # 評価時には勾配を計算しないevalモードにする\n","    for x, t in dataloader_valid:\n","        # WRITE ME\n","\n","        losses_valid.append(loss.tolist())\n","\n","        acc = torch.where(t - pred.to(\"cpu\") == 0, torch.ones_like(t), torch.zeros_like(t))\n","        valid_num += acc.size()[0]\n","        valid_true_num += acc.sum().item()\n","\n","    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n","        epoch,\n","        np.mean(losses_train),\n","        train_true_num/train_num,\n","        np.mean(losses_valid),\n","        valid_true_num/valid_num\n","    ))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yq3scS5j4Rt2"},"source":["mlp.eval()\n","\n","t_pred = []\n","for x in dataloader_test:\n","\n","    x = x.to(device)\n","\n","    # 順伝播\n","    y = mlp.forward(x)\n","\n","    # モデルの出力を予測値のスカラーに変換\n","    pred = y.argmax(1).tolist()\n","\n","    t_pred.extend(pred)\n","\n","submission = pd.Series(t_pred, name='label')\n","submission.to_csv('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210422/materials/submission_pred.csv', header=True, index_label='id')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"73f8DjqTCoTL"},"source":[""],"execution_count":null,"outputs":[]}]}