{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"chap05_homework.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python388jvsc74a57bd0514466fe9bdbb4465d0f72d486e68777ccb9801e0d08f857a8c5a4c505647bc4","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MUWcdth_khfN"},"source":["# 第3回講義 宿題"]},{"cell_type":"markdown","metadata":{"id":"gAjuP7I4lWyn"},"source":["## 課題\n","\n","今Lessonで学んだことを元に、MNISTのファッション版 (Fashion MNIST、クラス数10) を多層パーセプトロンによって分類してみましょう。\n","\n","Fashion MNISTの詳細については以下のリンクを参考にしてください。\n","\n","Fashion MNIST: https://github.com/zalandoresearch/fashion-mnist"]},{"cell_type":"markdown","metadata":{"id":"Cpiz19GRlZ_9"},"source":["### 目標値\n","\n","Accuracy 85%"]},{"cell_type":"markdown","metadata":{"id":"qSHeI_utleEN"},"source":["### ルール\n","\n","- 訓練データはx_train、 t_train、テストデータはx_testで与えられます。\n","- 予測ラベルは one_hot表現ではなく0~9のクラスラベル で表してください。\n","- **下のセルで指定されているx_train、t_train以外の学習データは使わないでください。**\n","- Pytorchを利用して構いません。\n","- ただし、**torch.nn.Conv2dのような高レベルのAPIは使用しないで下さい。**具体的には、nn.Parameter, nn.Module, nn.Sequential以外のnn系のAPIです。\n","- torchvision等で既に実装されているモデルも使用しないで下さい。"]},{"cell_type":"markdown","metadata":{"id":"diuec-_YluI6"},"source":["### 提出方法\n","\n","- 2つのファイルを提出していただきます。\n","  - テストデータ (x_test) に対する予測ラベルをcsvファイル (ファイル名: submission_pred.csv) で提出してください。\n","  - それに対応するpythonのコードをsubmission_code.pyとして提出してください (%%writefileコマンドなどを利用してください)。"]},{"cell_type":"markdown","metadata":{"id":"hofSzJsVlvKp"},"source":["### 評価方法\n","\n","- 予測ラベルのt_testに対する精度 (Accuracy) で評価します。\n","- 定時に採点しLeader Boardを更新します。(採点スケジュールは別アナウンス）\n","- 締切後の点数を最終的な評価とします。"]},{"cell_type":"markdown","metadata":{"id":"Cu4cmQtelx19"},"source":["### データの読み込み\n","\n","- この部分は修正しないでください"]},{"cell_type":"code","metadata":{"id":"EsLDDSUJkRx-"},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import inspect\n"," \n","nn_except = [\"Module\", \"Parameter\", \"Sequential\"]\n","for m in inspect.getmembers(nn):\n","    if not m[0] in nn_except and m[0][0:2] != \"__\":\n","        delattr(nn, m[0]) \n","\"\"\"\n","#学習データ\n","x_train = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210422/data/x_train.npy')\n","t_train = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210422/data/y_train.npy')\n","    \n","#テストデータ\n","x_test = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210422/data/x_test.npy')\n","\"\"\"\n","#学習データ\n","x_train = np.load('/home/sato.mizuki/deeplearningUT/Lecture03/data/x_train.npy')\n","t_train = np.load('/home/sato.mizuki/deeplearningUT/Lecture03/data/y_train.npy')\n","    \n","#テストデータ\n","x_test = np.load('/home/sato.mizuki/deeplearningUT/Lecture03/data/x_test.npy')\n","\n","class train_dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_train, t_train):\n","        self.x_train = x_train.reshape(-1, 784).astype('float32') / 255\n","        self.t_train = t_train\n","\n","    def __len__(self):\n","        return self.x_train.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.x_train[idx], dtype=torch.float), torch.tensor(t_train[idx], dtype=torch.long)\n","\n","class test_dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_test):\n","        self.x_test = x_test.reshape(-1, 784).astype('float32') / 255\n","\n","    def __len__(self):\n","        return self.x_test.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.x_test[idx], dtype=torch.float)\n","\n","trainval_data = train_dataset(x_train, t_train)\n","test_data = test_dataset(x_test)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UrSpHDIWOfK_"},"source":["### 多層パーセプトロンの実装"]},{"cell_type":"code","metadata":{"id":"sKAe0F36nSvU"},"source":["batch_size = 32\n","\n","val_size = 10000\n","train_size = len(trainval_data) - val_size\n","\n","train_data, val_data = torch.utils.data.random_split(trainval_data, [train_size, val_size])\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    train_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_valid = torch.utils.data.DataLoader(\n","    val_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_test = torch.utils.data.DataLoader(\n","    test_data,\n","    batch_size=batch_size,\n","    shuffle=False\n",")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"PADQiKNa2snb"},"source":["rng = np.random.RandomState(1234)\n","random_state = 42\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","def relu(x):\n","    x = torch.where(x>0, x, torch.zeros_like(x)) # WRITE ME\n","    return x\n","\n","\n","def softmax(x):\n","    x -= torch.cat([x.max(axis=1, keepdim=True).values]*x.size()[1], dim=1) # WRITE ME\n","    x_exp = torch.exp(x)\n","    return x_exp/torch.cat([x_exp.sum(dim=1, keepdim=True)] * x.size()[1], dim=1)\n","\n","class Dense(nn.Module):  # nn.Moduleを継承する\n","    def __init__(self, in_dim, out_dim, function=lambda x: x):# WRITE ME\n","        super().__init__()\n","\n","        self.W = nn.Parameter(torch.tensor(rng.uniform(\n","                        low=-np.sqrt(6/in_dim),\n","                        high=np.sqrt(6/in_dim),\n","                        size=(in_dim, out_dim)\n","                    ).astype('float32')))\n","        self.b = nn.Parameter(torch.tensor(np.zeros([out_dim]).astype('float32')))\n","        self.function = function\n","\n","    def forward(self, x):  # forwardをoverride\n","        return self.function(torch.matmul(x, self.W) + self.b)\n","        \n","\n","class MLP(nn.Module):  # nn.Moduleを継承する\n","    def __init__(self, in_dim, hid_dim, out_dim): # WRITE ME\n","        super(MLP, self).__init__()\n","        self.linear1 = Dense(in_dim, hid_dim)\n","        self.linear2 = Dense(hid_dim, out_dim)\n","\n","    def forward(self, x):\n","        x = relu(self.linear1(x))\n","        x = softmax(self.linear2(x))\n","        return x\n","\n","in_dim = 784\n","hid_dim = 200\n","out_dim = 10\n","lr = 0.001\n","n_epochs = 3600\n","\n","\n","mlp = MLP(in_dim, hid_dim, out_dim).to(device) # WRITE ME\n","\n","optimizer = optim.SGD(mlp.parameters(), lr=lr) # WRITE ME"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"nlOZuLu-328i"},"source":["for epoch in range(n_epochs):\n","    losses_train = []\n","    losses_valid = []\n","    train_num = 0\n","    train_true_num = 0\n","    valid_num = 0\n","    valid_true_num = 0\n","\n","    mlp.train()  # 訓練時には勾配を計算するtrainモードにする\n","    for x, t in dataloader_train:\n","        # WRITE ME\n","        true = t.tolist()\n","\n","        t_hot = torch.eye(10)[t]\n","        #テンソルGPUに移動\n","        x = x.to(device)\n","        t_hot = t_hot.to(device)\n","        \n","        #順伝搬\n","        y = mlp.forward(x)\n","        \n","        #誤差の計算\n","        loss = -(t_hot*torch.log(y)).sum(axis=1).mean()\n","\n","        #誤差の逆伝搬\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        #パラメータの更新\n","        optimizer.step()\n","\n","        # モデルの出力を予測値のスカラーに変換\n","        pred = y.argmax(1)\n","\n","        losses_train.append(loss.tolist())\n","\n","        acc = torch.where(t - pred.to(\"cpu\") == 0, torch.ones_like(t), torch.zeros_like(t))\n","        train_num += acc.size()[0]\n","        train_true_num += acc.sum().item()\n","\n","    mlp.eval()  # 評価時には勾配を計算しないevalモードにする\n","    for x, t in dataloader_valid:\n","        # WRITE ME\n","        true = t.tolist()\n","\n","        t_hot = torch.eye(10)[t]\n","        #テンソルGPUに移動\n","        x = x.to(device)\n","        t_hot = t_hot.to(device)\n","        \n","        #順伝搬\n","        y = mlp.forward(x)\n","        \n","        #誤差の計算\n","        loss = -(t_hot*torch.log(y)).sum(axis=1).mean()\n","\n","        #誤差の逆伝搬\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        #パラメータの更新\n","        optimizer.step()\n","\n","        # モデルの出力を予測値のスカラーに変換\n","        pred = y.argmax(1)\n","\n","        losses_valid.append(loss.tolist())\n","\n","        acc = torch.where(t - pred.to(\"cpu\") == 0, torch.ones_like(t), torch.zeros_like(t))\n","        valid_num += acc.size()[0]\n","        valid_true_num += acc.sum().item()\n","\n","    if epoch%100 == 0:\n","        print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n","            epoch,\n","            np.mean(losses_train),\n","            train_true_num/train_num,\n","            np.mean(losses_valid),\n","            valid_true_num/valid_num\n","        ))"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["EPOCH: 0, Train [Loss: 1.431, Accuracy: 0.572], Valid [Loss: 0.992, Accuracy: 0.700]\n","EPOCH: 100, Train [Loss: 0.357, Accuracy: 0.877], Valid [Loss: 0.352, Accuracy: 0.878]\n","EPOCH: 200, Train [Loss: 0.304, Accuracy: 0.895], Valid [Loss: 0.299, Accuracy: 0.895]\n","EPOCH: 300, Train [Loss: 0.270, Accuracy: 0.906], Valid [Loss: 0.263, Accuracy: 0.908]\n","EPOCH: 400, Train [Loss: 0.243, Accuracy: 0.916], Valid [Loss: 0.235, Accuracy: 0.916]\n","EPOCH: 500, Train [Loss: 0.221, Accuracy: 0.925], Valid [Loss: 0.212, Accuracy: 0.926]\n","EPOCH: 600, Train [Loss: 0.201, Accuracy: 0.932], Valid [Loss: 0.192, Accuracy: 0.935]\n","EPOCH: 700, Train [Loss: 0.183, Accuracy: 0.939], Valid [Loss: 0.175, Accuracy: 0.939]\n","EPOCH: 800, Train [Loss: 0.167, Accuracy: 0.946], Valid [Loss: 0.160, Accuracy: 0.945]\n","EPOCH: 900, Train [Loss: 0.153, Accuracy: 0.951], Valid [Loss: 0.145, Accuracy: 0.954]\n","EPOCH: 1000, Train [Loss: 0.140, Accuracy: 0.956], Valid [Loss: 0.133, Accuracy: 0.956]\n","EPOCH: 1100, Train [Loss: 0.128, Accuracy: 0.962], Valid [Loss: 0.121, Accuracy: 0.961]\n","EPOCH: 1200, Train [Loss: 0.117, Accuracy: 0.966], Valid [Loss: 0.111, Accuracy: 0.965]\n","EPOCH: 1300, Train [Loss: 0.107, Accuracy: 0.970], Valid [Loss: 0.102, Accuracy: 0.970]\n","EPOCH: 1400, Train [Loss: 0.098, Accuracy: 0.973], Valid [Loss: 0.093, Accuracy: 0.974]\n","EPOCH: 1500, Train [Loss: 0.089, Accuracy: 0.977], Valid [Loss: 0.085, Accuracy: 0.977]\n","EPOCH: 1600, Train [Loss: 0.082, Accuracy: 0.979], Valid [Loss: 0.078, Accuracy: 0.981]\n","EPOCH: 1700, Train [Loss: 0.075, Accuracy: 0.982], Valid [Loss: 0.072, Accuracy: 0.983]\n","EPOCH: 1800, Train [Loss: 0.069, Accuracy: 0.985], Valid [Loss: 0.065, Accuracy: 0.985]\n","EPOCH: 1900, Train [Loss: 0.063, Accuracy: 0.986], Valid [Loss: 0.060, Accuracy: 0.987]\n","EPOCH: 2000, Train [Loss: 0.058, Accuracy: 0.988], Valid [Loss: 0.055, Accuracy: 0.990]\n","EPOCH: 2100, Train [Loss: 0.053, Accuracy: 0.990], Valid [Loss: 0.050, Accuracy: 0.991]\n","EPOCH: 2200, Train [Loss: 0.049, Accuracy: 0.991], Valid [Loss: 0.047, Accuracy: 0.993]\n","EPOCH: 2300, Train [Loss: 0.045, Accuracy: 0.993], Valid [Loss: 0.043, Accuracy: 0.993]\n","EPOCH: 2400, Train [Loss: 0.042, Accuracy: 0.994], Valid [Loss: 0.039, Accuracy: 0.994]\n","EPOCH: 2500, Train [Loss: 0.039, Accuracy: 0.995], Valid [Loss: 0.037, Accuracy: 0.994]\n","EPOCH: 2600, Train [Loss: 0.036, Accuracy: 0.995], Valid [Loss: 0.034, Accuracy: 0.996]\n","EPOCH: 2700, Train [Loss: 0.033, Accuracy: 0.996], Valid [Loss: 0.031, Accuracy: 0.996]\n","EPOCH: 2800, Train [Loss: 0.031, Accuracy: 0.997], Valid [Loss: 0.029, Accuracy: 0.997]\n","EPOCH: 2900, Train [Loss: 0.029, Accuracy: 0.997], Valid [Loss: 0.027, Accuracy: 0.997]\n","EPOCH: 3000, Train [Loss: 0.027, Accuracy: 0.998], Valid [Loss: 0.025, Accuracy: 0.998]\n","EPOCH: 3100, Train [Loss: 0.025, Accuracy: 0.998], Valid [Loss: 0.024, Accuracy: 0.998]\n","EPOCH: 3200, Train [Loss: 0.023, Accuracy: 0.998], Valid [Loss: 0.022, Accuracy: 0.999]\n","EPOCH: 3300, Train [Loss: 0.022, Accuracy: 0.999], Valid [Loss: 0.021, Accuracy: 0.999]\n","EPOCH: 3400, Train [Loss: 0.020, Accuracy: 0.999], Valid [Loss: 0.019, Accuracy: 0.999]\n","EPOCH: 3500, Train [Loss: 0.019, Accuracy: 0.999], Valid [Loss: 0.018, Accuracy: 0.999]\n"]}]},{"cell_type":"code","metadata":{"id":"Yq3scS5j4Rt2"},"source":["mlp.eval()\n","\n","t_pred = []\n","for x in dataloader_test:\n","\n","    x = x.to(device)\n","\n","    # 順伝播\n","    y = mlp.forward(x)\n","\n","    # モデルの出力を予測値のスカラーに変換\n","    pred = y.argmax(1).tolist()\n","\n","    t_pred.extend(pred)\n","\n","submission = pd.Series(t_pred, name='label')\n","\"\"\"\n","submission.to_csv('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210422/materials/submission_pred.csv', header=True, index_label='id')\n","\"\"\"\n","import os\n","os.makedirs('output', exist_ok=True)\n","submission.to_csv('output/submission_pred_3600.csv', header=True, index_label='id')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"73f8DjqTCoTL"},"source":[],"execution_count":null,"outputs":[]}]}