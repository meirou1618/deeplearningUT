{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"chap05_homework.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python388jvsc74a57bd0514466fe9bdbb4465d0f72d486e68777ccb9801e0d08f857a8c5a4c505647bc4","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MUWcdth_khfN"},"source":["# 第3回講義 宿題"]},{"cell_type":"markdown","metadata":{"id":"gAjuP7I4lWyn"},"source":["## 課題\n","\n","今Lessonで学んだことを元に、MNISTのファッション版 (Fashion MNIST、クラス数10) を多層パーセプトロンによって分類してみましょう。\n","\n","Fashion MNISTの詳細については以下のリンクを参考にしてください。\n","\n","Fashion MNIST: https://github.com/zalandoresearch/fashion-mnist"]},{"cell_type":"markdown","metadata":{"id":"Cpiz19GRlZ_9"},"source":["### 目標値\n","\n","Accuracy 85%"]},{"cell_type":"markdown","metadata":{"id":"qSHeI_utleEN"},"source":["### ルール\n","\n","- 訓練データはx_train、 t_train、テストデータはx_testで与えられます。\n","- 予測ラベルは one_hot表現ではなく0~9のクラスラベル で表してください。\n","- **下のセルで指定されているx_train、t_train以外の学習データは使わないでください。**\n","- Pytorchを利用して構いません。\n","- ただし、**torch.nn.Conv2dのような高レベルのAPIは使用しないで下さい。**具体的には、nn.Parameter, nn.Module, nn.Sequential以外のnn系のAPIです。\n","- torchvision等で既に実装されているモデルも使用しないで下さい。"]},{"cell_type":"markdown","metadata":{"id":"diuec-_YluI6"},"source":["### 提出方法\n","\n","- 2つのファイルを提出していただきます。\n","  - テストデータ (x_test) に対する予測ラベルをcsvファイル (ファイル名: submission_pred.csv) で提出してください。\n","  - それに対応するpythonのコードをsubmission_code.pyとして提出してください (%%writefileコマンドなどを利用してください)。"]},{"cell_type":"markdown","metadata":{"id":"hofSzJsVlvKp"},"source":["### 評価方法\n","\n","- 予測ラベルのt_testに対する精度 (Accuracy) で評価します。\n","- 定時に採点しLeader Boardを更新します。(採点スケジュールは別アナウンス）\n","- 締切後の点数を最終的な評価とします。"]},{"cell_type":"markdown","metadata":{"id":"Cu4cmQtelx19"},"source":["### データの読み込み\n","\n","- この部分は修正しないでください"]},{"cell_type":"code","metadata":{"id":"EsLDDSUJkRx-"},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import inspect\n"," \n","nn_except = [\"Module\", \"Parameter\", \"Sequential\"]\n","for m in inspect.getmembers(nn):\n","    if not m[0] in nn_except and m[0][0:2] != \"__\":\n","        delattr(nn, m[0]) \n","\"\"\"\n","#学習データ\n","x_train = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210422/data/x_train.npy')\n","t_train = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210422/data/y_train.npy')\n","    \n","#テストデータ\n","x_test = np.load('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210422/data/x_test.npy')\n","\"\"\"\n","#学習データ\n","x_train = np.load('/home/sato.mizuki/deeplearningUT/Lecture03/data/x_train.npy')\n","t_train = np.load('/home/sato.mizuki/deeplearningUT/Lecture03/data/y_train.npy')\n","    \n","#テストデータ\n","x_test = np.load('/home/sato.mizuki/deeplearningUT/Lecture03/data/x_test.npy')\n","\n","class train_dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_train, t_train):\n","        self.x_train = x_train.reshape(-1, 784).astype('float32') / 255\n","        self.t_train = t_train\n","\n","    def __len__(self):\n","        return self.x_train.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.x_train[idx], dtype=torch.float), torch.tensor(t_train[idx], dtype=torch.long)\n","\n","class test_dataset(torch.utils.data.Dataset):\n","    def __init__(self, x_test):\n","        self.x_test = x_test.reshape(-1, 784).astype('float32') / 255\n","\n","    def __len__(self):\n","        return self.x_test.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.x_test[idx], dtype=torch.float)\n","\n","trainval_data = train_dataset(x_train, t_train)\n","test_data = test_dataset(x_test)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UrSpHDIWOfK_"},"source":["### 多層パーセプトロンの実装"]},{"cell_type":"code","metadata":{"id":"sKAe0F36nSvU"},"source":["batch_size = 32\n","\n","val_size = 10000\n","train_size = len(trainval_data) - val_size\n","\n","train_data, val_data = torch.utils.data.random_split(trainval_data, [train_size, val_size])\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    train_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_valid = torch.utils.data.DataLoader(\n","    val_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_test = torch.utils.data.DataLoader(\n","    test_data,\n","    batch_size=batch_size,\n","    shuffle=False\n",")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"PADQiKNa2snb"},"source":["rng = np.random.RandomState(1234)\n","random_state = 42\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","def relu(x):\n","    x = torch.where(x>0, x, torch.zeros_like(x)) # WRITE ME\n","    return x\n","\n","\n","def softmax(x):\n","    x -= torch.cat([x.max(axis=1, keepdim=True).values]*x.size()[1], dim=1) # WRITE ME\n","    x_exp = torch.exp(x)\n","    return x_exp/torch.cat([x_exp.sum(dim=1, keepdim=True)] * x.size()[1], dim=1)\n","\n","class Dense(nn.Module):  # nn.Moduleを継承する\n","    def __init__(self, in_dim, out_dim, function=lambda x: x):# WRITE ME\n","        super().__init__()\n","\n","        self.W = nn.Parameter(torch.tensor(rng.uniform(\n","                        low=-np.sqrt(6/in_dim),\n","                        high=np.sqrt(6/in_dim),\n","                        size=(in_dim, out_dim)\n","                    ).astype('float32')))\n","        self.b = nn.Parameter(torch.tensor(np.zeros([out_dim]).astype('float32')))\n","        self.function = function\n","\n","    def forward(self, x):  # forwardをoverride\n","        return self.function(torch.matmul(x, self.W) + self.b)\n","        \n","\n","class MLP(nn.Module):  # nn.Moduleを継承する\n","    def __init__(self, in_dim, hid_dim, out_dim): # WRITE ME\n","        super(MLP, self).__init__()\n","        self.linear1 = Dense(in_dim, hid_dim)\n","        self.linear2 = Dense(hid_dim, out_dim)\n","\n","    def forward(self, x):\n","        x = relu(self.linear1(x))\n","        x = softmax(self.linear2(x))\n","        return x\n","\n","in_dim = 784\n","hid_dim = 200\n","out_dim = 10\n","lr = 0.001\n","n_epochs = 2000\n","\n","\n","mlp = MLP(in_dim, hid_dim, out_dim).to(device) # WRITE ME\n","\n","optimizer = optim.SGD(mlp.parameters(), lr=lr) # WRITE ME"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"nlOZuLu-328i"},"source":["for epoch in range(n_epochs):\n","    losses_train = []\n","    losses_valid = []\n","    train_num = 0\n","    train_true_num = 0\n","    valid_num = 0\n","    valid_true_num = 0\n","\n","    mlp.train()  # 訓練時には勾配を計算するtrainモードにする\n","    for x, t in dataloader_train:\n","        # WRITE ME\n","        true = t.tolist()\n","\n","        t_hot = torch.eye(10)[t]\n","        #テンソルGPUに移動\n","        x = x.to(device)\n","        t_hot = t_hot.to(device)\n","        \n","        #順伝搬\n","        y = mlp.forward(x)\n","        \n","        #誤差の計算\n","        loss = -(t_hot*torch.log(y)).sum(axis=1).mean()\n","\n","        #誤差の逆伝搬\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        #パラメータの更新\n","        optimizer.step()\n","\n","        # モデルの出力を予測値のスカラーに変換\n","        pred = y.argmax(1)\n","\n","        losses_train.append(loss.tolist())\n","\n","        acc = torch.where(t - pred.to(\"cpu\") == 0, torch.ones_like(t), torch.zeros_like(t))\n","        train_num += acc.size()[0]\n","        train_true_num += acc.sum().item()\n","\n","    mlp.eval()  # 評価時には勾配を計算しないevalモードにする\n","    for x, t in dataloader_valid:\n","        # WRITE ME\n","        true = t.tolist()\n","\n","        t_hot = torch.eye(10)[t]\n","        #テンソルGPUに移動\n","        x = x.to(device)\n","        t_hot = t_hot.to(device)\n","        \n","        #順伝搬\n","        y = mlp.forward(x)\n","        \n","        #誤差の計算\n","        loss = -(t_hot*torch.log(y)).sum(axis=1).mean()\n","\n","        #誤差の逆伝搬\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        #パラメータの更新\n","        optimizer.step()\n","\n","        # モデルの出力を予測値のスカラーに変換\n","        pred = y.argmax(1)\n","\n","        losses_valid.append(loss.tolist())\n","\n","        acc = torch.where(t - pred.to(\"cpu\") == 0, torch.ones_like(t), torch.zeros_like(t))\n","        valid_num += acc.size()[0]\n","        valid_true_num += acc.sum().item()\n","\n","    if epoch%100 == 0:\n","        print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n","            epoch,\n","            np.mean(losses_train),\n","            train_true_num/train_num,\n","            np.mean(losses_valid),\n","            valid_true_num/valid_num\n","        ))"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["EPOCH: 0, Train [Loss: 1.430, Accuracy: 0.577], Valid [Loss: 1.000, Accuracy: 0.696]\n","EPOCH: 100, Train [Loss: 0.354, Accuracy: 0.879], Valid [Loss: 0.368, Accuracy: 0.870]\n","EPOCH: 200, Train [Loss: 0.301, Accuracy: 0.896], Valid [Loss: 0.315, Accuracy: 0.888]\n","EPOCH: 300, Train [Loss: 0.267, Accuracy: 0.907], Valid [Loss: 0.278, Accuracy: 0.902]\n","EPOCH: 400, Train [Loss: 0.240, Accuracy: 0.917], Valid [Loss: 0.249, Accuracy: 0.912]\n","EPOCH: 500, Train [Loss: 0.217, Accuracy: 0.925], Valid [Loss: 0.226, Accuracy: 0.921]\n","EPOCH: 600, Train [Loss: 0.198, Accuracy: 0.934], Valid [Loss: 0.206, Accuracy: 0.926]\n","EPOCH: 700, Train [Loss: 0.180, Accuracy: 0.940], Valid [Loss: 0.188, Accuracy: 0.934]\n","EPOCH: 800, Train [Loss: 0.165, Accuracy: 0.947], Valid [Loss: 0.171, Accuracy: 0.942]\n","EPOCH: 900, Train [Loss: 0.151, Accuracy: 0.952], Valid [Loss: 0.158, Accuracy: 0.949]\n","EPOCH: 1000, Train [Loss: 0.137, Accuracy: 0.957], Valid [Loss: 0.144, Accuracy: 0.954]\n","EPOCH: 1100, Train [Loss: 0.126, Accuracy: 0.962], Valid [Loss: 0.132, Accuracy: 0.957]\n","EPOCH: 1200, Train [Loss: 0.115, Accuracy: 0.966], Valid [Loss: 0.120, Accuracy: 0.963]\n","EPOCH: 1300, Train [Loss: 0.105, Accuracy: 0.970], Valid [Loss: 0.109, Accuracy: 0.967]\n","EPOCH: 1400, Train [Loss: 0.096, Accuracy: 0.974], Valid [Loss: 0.100, Accuracy: 0.972]\n","EPOCH: 1500, Train [Loss: 0.088, Accuracy: 0.977], Valid [Loss: 0.091, Accuracy: 0.974]\n","EPOCH: 1600, Train [Loss: 0.081, Accuracy: 0.980], Valid [Loss: 0.084, Accuracy: 0.978]\n","EPOCH: 1700, Train [Loss: 0.074, Accuracy: 0.982], Valid [Loss: 0.076, Accuracy: 0.980]\n","EPOCH: 1800, Train [Loss: 0.068, Accuracy: 0.985], Valid [Loss: 0.070, Accuracy: 0.983]\n","EPOCH: 1900, Train [Loss: 0.062, Accuracy: 0.987], Valid [Loss: 0.064, Accuracy: 0.986]\n"]}]},{"cell_type":"code","metadata":{"id":"Yq3scS5j4Rt2"},"source":["mlp.eval()\n","\n","t_pred = []\n","for x in dataloader_test:\n","\n","    x = x.to(device)\n","\n","    # 順伝播\n","    y = mlp.forward(x)\n","\n","    # モデルの出力を予測値のスカラーに変換\n","    pred = y.argmax(1).tolist()\n","\n","    t_pred.extend(pred)\n","\n","submission = pd.Series(t_pred, name='label')\n","\"\"\"\n","submission.to_csv('drive/My Drive/Colab Notebooks/DLBasics2021_colab/Lecture_20210422/materials/submission_pred.csv', header=True, index_label='id')\n","\"\"\"\n","import os\n","os.makedirs('output', exist_ok=True)\n","submission.to_csv('output/submission_pred.csv', header=True, index_label='id')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"73f8DjqTCoTL"},"source":[],"execution_count":null,"outputs":[]}]}